import os
import time
import torch
import pandas as pd
import numpy as np
import requests
from datetime import datetime
from pytorch_forecasting import DeepAR, TimeSeriesDataSet
import warnings
from collections import deque

warnings.filterwarnings("ignore")

# â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€
symbol = "DOGEUSDT"
seq_len = 60
pred_len = 10
interval = "1m"
thresh_roi = 0.001
slippage = 0.0005
fee_rate = 0.0004
take_profit_roi = 0.01
stop_loss_roi = -0.01
initial_capital = 1000.0
capital = initial_capital
SLEEP_SEC = 60
LOG_FILE = f"{symbol}_trade_log.csv"
SELECTION_MODE = "confidence"  # ì„ íƒ: "confidence" ë˜ëŠ” "roi_ratio"



# â”€â”€â”€â”€â”€ ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™” â”€â”€â”€â”€â”€
if not os.path.exists(LOG_FILE):
    pd.DataFrame(columns=["timestamp", "event", "direction", "price", "roi", "value", "capital", "note"]).to_csv(LOG_FILE, index=False)

def log_event(event, direction, price, roi, value, capital, note=""):
    log_entry = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "event": event,
        "direction": direction,
        "price": price,
        "roi": roi,
        "value": value,
        "capital": capital,
        "note": note
    }
    pd.DataFrame([log_entry]).to_csv(LOG_FILE, mode="a", header=False, index=False)

# â”€â”€â”€â”€â”€ ëª¨ë¸ ë¡œë”© â”€â”€â”€â”€â”€
df_all = pd.read_csv(f"{symbol}_deepar_input.csv").dropna()
deepar_dataset = TimeSeriesDataSet(
    df_all,
    time_idx="time_idx",
    target="log_return",
    group_ids=["series_id"],
    max_encoder_length=seq_len,
    max_prediction_length=pred_len,
    time_varying_known_reals=["time_idx", "volume"],
    time_varying_unknown_reals=["log_return"],
    static_categoricals=[],
    add_relative_time_idx=True,
    add_target_scales=True,
    add_encoder_length=True,
)

model = DeepAR.load_from_checkpoint(f"{symbol}_deepar_model.ckpt")
model.eval()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# â”€â”€â”€â”€â”€ í•¨ìˆ˜ ì •ì˜ â”€â”€â”€â”€â”€
def fetch_ohlcv(symbol, limit=2):
    url = "https://fapi.binance.com/fapi/v1/klines"
    params = {"symbol": symbol, "interval": interval, "limit": limit}
    try:
        res = requests.get(url, params=params).json()
        columns = [
            "timestamp", "open", "high", "low", "close", "volume",
            "close_time", "quote_asset_volume", "num_trades",
            "taker_buy_base_volume", "taker_buy_quote_volume", "ignore"
        ]
        df = pd.DataFrame(res, columns=columns)
        df = df.astype({"close": float, "volume": float})
        df["log_return"] = np.log(df["close"] / df["close"].shift(1))
        df.dropna(inplace=True)
        return df
    except Exception as e:
        print(f"[ERROR] OHLCV fetch ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def predict_with_uncertainty(df, now_price):
    df = df.copy().reset_index(drop=True)
    df["time_idx"] = np.arange(len(df))
    df["series_id"] = symbol
    ds = TimeSeriesDataSet.from_dataset(deepar_dataset, df, predict=True, stop_randomization=True)
    dl = ds.to_dataloader(train=False, batch_size=1)

    raw = model.predict(dl, mode="raw")[0]
    log_returns_all = raw.cpu().numpy()[0]
    log_returns_all = log_returns_all[:, :pred_len]

    pct_returns_all = np.exp(log_returns_all) - 1
    cum_returns_all = np.cumsum(np.log1p(pct_returns_all), axis=1)
    pred_prices_all = now_price * np.exp(cum_returns_all)

    avg_prices = np.mean(pred_prices_all, axis=0)
    lower_band = np.percentile(pred_prices_all, 10, axis=0)
    upper_band = np.percentile(pred_prices_all, 90, axis=0)
    avg_roi = np.mean(pct_returns_all, axis=0)

    return avg_prices, lower_band, upper_band, avg_roi

# â”€â”€â”€â”€â”€ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™” â”€â”€â”€â”€â”€
is_holding = False
entry_price = None
entry_time = None
direction = None
target_hold_seconds = None
target_price = None

# â”€â”€â”€â”€â”€ ì‹¤ì‹œê°„ ë£¨í”„ ì‹œì‘ ì „ ë°ì´í„° ì´ˆê¸°í™” â”€â”€â”€â”€â”€
data_queue = deque(maxlen=seq_len + pred_len)
print("[INFO] ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
while True:
    df_init = fetch_ohlcv(symbol, limit=seq_len + pred_len + 10)
    if not df_init.empty and df_init.shape[0] >= seq_len + pred_len:
        for _, row in df_init.tail(seq_len + pred_len).iterrows():
            data_queue.append(row)
        break
    print("[WAIT] ë°ì´í„° ë¶€ì¡±, ì¬ì‹œë„ ì¤‘...")
    time.sleep(3)
print("[INFO] ì´ˆê¸°í™” ì™„ë£Œ. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œì‘")

# â”€â”€â”€â”€â”€ ì‹¤ì‹œê°„ ë£¨í”„ â”€â”€â”€â”€â”€
# â”€â”€â”€â”€â”€ ì‹¤ì‹œê°„ ë£¨í”„ â”€â”€â”€â”€â”€
while True:
    df_new = fetch_ohlcv(symbol, limit=2)
    if df_new.empty:
        print("[WARN] ìµœì‹  ë°ì´í„° ì—†ìŒ")
        if not is_holding:
            time.sleep(SLEEP_SEC)
        continue

    data_queue.append(df_new.iloc[-1])
    df_seq = pd.DataFrame(list(data_queue))

    if len(df_seq) < seq_len + pred_len:
        print(f"[{datetime.now()}] â³ ë°ì´í„° ë¶€ì¡±")
        if not is_holding:
            time.sleep(SLEEP_SEC)
        continue

    if not is_holding:
        now_price = df_seq["close"].iloc[-pred_len - 1]
        avg_prices, lower_band, upper_band, avg_roi_seq = predict_with_uncertainty(df_seq, now_price)

        # ğŸ¯ ê°€ì¥ ROI í° ì‹œì  ê¸°ì¤€
        target_idx = np.argmax(np.abs(avg_roi_seq))
        target_roi = avg_roi_seq[target_idx]
        target_price = avg_prices[target_idx]
        target_min = target_idx + 1

        print("=" * 80)
        print(f"[{datetime.now()}] ğŸ”® Predicted ROI Sequence: {[f'{x*100:.4f}%' for x in avg_roi_seq]}")
        print(f"ğŸ¯ Target ROI = {target_roi * 100:.4f}% @ {target_min}ë¶„ í›„ â†’ ì˜ˆìƒ ê°€ê²©: {target_price:.6f} | í˜„ì¬ê°€: {now_price:.6f}")
        print("=" * 80)

        if abs(target_roi) > thresh_roi:
            entry_price = now_price * (1 + slippage)
            entry_time = datetime.now()
            direction = "LONG" if target_roi > 0 else "SHORT"
            is_holding = True
            target_hold_seconds = target_min * 60

            print(f"ğŸš€ ENTRY [{direction}] @ {entry_price:.6f} | ì²­ì‚° ëª©í‘œ {target_min}ë¶„ ë’¤ | ì˜ˆìƒ ROI {target_roi*100:.3f}%")
            log_event("ENTRY", direction, entry_price, 0, capital, capital, f"target_min={target_min} ROI={target_roi:.5f}")

        time.sleep(SLEEP_SEC)

    else:
        # ì‹¤ì‹œê°„ ì²­ì‚° ê°ì‹œ
        latest_price = df_new["close"].iloc[-1]
        roi = (latest_price - entry_price) / entry_price if direction == "LONG" else (entry_price - latest_price) / entry_price
        value = capital * (1 + roi - fee_rate)
        held_seconds = (datetime.now() - entry_time).seconds

        print(f"â³ MONITOR [{direction}] @ {latest_price:.6f} ROI={roi*100:.4f}%  Value=${value:.4f} Held={held_seconds}s")

        if held_seconds < target_hold_seconds:
            # ğŸ¯ ì˜ˆìƒ ROI ë„ë‹¬ ì‹œ ì¡°ê¸° ì²­ì‚°
            if (direction == "LONG" and roi >= target_roi) or (direction == "SHORT" and roi >= abs(target_roi)):
                print(f"ğŸ’° EARLY EXIT by TARGET ROI [{direction}] @ {latest_price:.6f} ROI={roi*100:.4f}%")
                log_event("EXIT_EARLY", direction, latest_price, roi, value, capital)
                capital = value
                is_holding = False
        else:
            # âŒ› ì‹œê°„ì´ ì§€ë‚¬ìœ¼ë©´ TP/SLë¡œ ì²­ì‚°
            if roi >= take_profit_roi:
                print(f"ğŸ’° TAKE PROFIT [{direction}] @ {latest_price:.6f} Gain=${value - capital:.2f}")
                log_event("EXIT_TP", direction, latest_price, roi, value, capital)
                capital = value
                is_holding = False
            elif roi <= stop_loss_roi:
                print(f"ğŸ›‘ STOP LOSS [{direction}] @ {latest_price:.6f} Loss=${value - capital:.2f}")
                log_event("EXIT_SL", direction, latest_price, roi, value, capital)
                capital = value
                is_holding = False
            else:
                print(f"â± HOLDING after target duration... TP/SL ì¡°ê±´ ëŒ€ê¸° ì¤‘")
