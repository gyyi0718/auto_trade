
# paper_trading.py
# -*- coding: utf-8 -*-
"""
TCN ëª¨ë¸ ê¸°ë°˜ í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ (ì‹¬ë³¼ë³„ ëª¨ë¸ ì‚¬ìš©)
- ê° ì‹¬ë³¼ë§ˆë‹¤ ë³„ë„ì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ
- ì‹¤ì‹œê°„ ì‹ í˜¸ ê¸°ë°˜ ìë™ ë§¤ë§¤ ì‹œë®¬ë ˆì´ì…˜
- ë ˆë²„ë¦¬ì§€ ê±°ë˜ ì‹œë®¬ë ˆì´ì…˜
- í¬ì§€ì…˜ ê´€ë¦¬ ë° ì†ìµ ê³„ì‚°
- ê±°ë˜ ë‚´ì—­ ì €ì¥
"""
import os
import time
import json
import warnings
from datetime import datetime
from typing import Optional, Dict, List
from dataclasses import dataclass, asdict
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import requests
import certifi

warnings.filterwarnings("ignore")
os.environ["SSL_CERT_FILE"] = certifi.where()
os.environ["REQUESTS_CA_BUNDLE"] = certifi.where()

# ===== CONFIG =====
SYMBOLS = os.getenv("SYMBOLS", "FLUXUSDT").split(
    ",")
INTERVAL_SEC = int(os.getenv("INTERVAL_SEC", "2"))

# âœ… ì‹¬ë³¼ë³„ ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
# ë°©ë²• 1: ê°œë³„ ì§€ì •
MODEL_PATHS = {
    "HUSDT": "D:/ygy_work/coin/multimodel/models_improved/h",
    "FLUXUSDT": "D:/ygy_work/coin/multimodel/models_improved/flux",
    "BTCUSDT": "D:/ygy_work/coin/multimodel/models_improved/btc",
    "ETHUSDT": "D:/ygy_work/coin/multimodel/models_improved/eth",
    "SOLUSDT": "D:/ygy_work/coin/multimodel/models_improved/sol",
    "PYRUSDT": "D:/ygy_work/coin/multimodel/models_improved/pyr",
    "GIGGLEUSDT": "D:/ygy_work/coin/multimodel/models_improved/giggle"
}

# ë°©ë²• 2: íŒ¨í„´ ê¸°ë°˜ ìë™ ìƒì„± (ì„ íƒì‚¬í•­)
# MODEL_DIR = "D:/ygy_work/coin/multimodel/models_5min/"
# MODEL_PATHS = {symbol: f"{MODEL_DIR}{symbol}_best.ckpt" for symbol in SYMBOLS}
DEBUG_MODE = os.getenv("DEBUG", "").strip()
SYMBOLS_ENV = os.getenv("SYMBOLS", "").strip()

CONF_THRESHOLD = float(os.getenv("CONF_THRESHOLD", "0.5"))
USE_TESTNET = os.getenv("USE_TESTNET", "0") == "1"

# í˜ì´í¼ íŠ¸ë ˆì´ë”© ì„¤ì •
INITIAL_CAPITAL = float(os.getenv("INITIAL_CAPITAL", "1000"))  # ì´ˆê¸° ìë³¸ (USDT)
POSITION_SIZE_PCT = float(os.getenv("POSITION_SIZE_PCT", "0.1"))  # í¬ì§€ì…˜ í¬ê¸° (10%)
LEVERAGE = int(os.getenv("LEVERAGE", "20"))  # ë ˆë²„ë¦¬ì§€ ë°°ìœ¨
MAX_POSITIONS = int(os.getenv("MAX_POSITIONS", "5"))  # ìµœëŒ€ ë™ì‹œ í¬ì§€ì…˜
STOP_LOSS_PCT = float(os.getenv("STOP_LOSS_PCT", "0.02"))  # ì†ì ˆ (2%)
TAKE_PROFIT_PCT = float(os.getenv("TAKE_PROFIT_PCT", "0.03"))  # ìµì ˆ (3%)
MAX_HOLD_MINUTES = int(os.getenv("MAX_HOLD_MINUTES", "30"))  # ìµœëŒ€ ë³´ìœ  ì‹œê°„
LIQUIDATION_BUFFER = float(os.getenv("LIQUIDATION_BUFFER", "0.8"))  # ì²­ì‚° ë²„í¼ (80%)
TRADE_LOG_FILE = os.getenv("TRADE_LOG_FILE", "trades.json")

# ğŸ”§ ê°€ê²© ë° ROE ê²€ì¦ ì„¤ì • (ROE 2000% ë²„ê·¸ ë°©ì§€)
MAX_PRICE_CHANGE_PCT = 50.0  # ìµœëŒ€ ê°€ê²© ë³€ë™ë¥  50%
MAX_ROE_LIMIT = 100.0  # ROE ìƒí•œì„  Â±100%
MIN_PRICE_RATIO = 0.5  # ìµœì†Œ ê°€ê²© ë¹„ìœ¨ (ì§„ì…ê°€ ëŒ€ë¹„ 50%)
MAX_PRICE_RATIO = 2.0  # ìµœëŒ€ ê°€ê²© ë¹„ìœ¨ (ì§„ì…ê°€ ëŒ€ë¹„ 200%)


# ===== ê°€ê²© ê²€ì¦ í•¨ìˆ˜ =====
def validate_price(current_price: float, entry_price: float, symbol: str) -> tuple[bool, str]:
    """ê°€ê²© ìœ íš¨ì„± ê²€ì¦ - ROE 2000% ë²„ê·¸ ë°©ì§€"""

    # 1. ê°€ê²©ì´ 0ì´ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš°
    if current_price <= 0:
        return False, f"Invalid price: {current_price}"

    # 2. ì§„ì…ê°€ ëŒ€ë¹„ ë„ˆë¬´ í° ë³€ë™
    price_ratio = current_price / entry_price
    if price_ratio < MIN_PRICE_RATIO or price_ratio > MAX_PRICE_RATIO:
        return False, f"Abnormal price change: {price_ratio:.2%} (entry: ${entry_price:.4f}, current: ${current_price:.4f})"

    # 3. ë³€ë™ë¥  ì²´í¬
    change_pct = abs(price_ratio - 1) * 100
    if change_pct > MAX_PRICE_CHANGE_PCT:
        return False, f"Price change too large: {change_pct:.1f}%"

    return True, ""


# ===== ë°ì´í„° í´ë˜ìŠ¤ =====
@dataclass
class Position:
    """í¬ì§€ì…˜ ì •ë³´"""
    symbol: str
    direction: str  # "Long" or "Short"
    entry_price: float
    quantity: float
    entry_time: datetime
    stop_loss: float
    take_profit: float
    leverage: int
    margin: float  # ì‹¤ì œ ì‚¬ìš©í•œ ì¦ê±°ê¸ˆ
    liquidation_price: float  # ì²­ì‚°ê°€

    def get_pnl(self, current_price: float) -> float:
        """ì†ìµ ê³„ì‚° (ë ˆë²„ë¦¬ì§€ ì ìš©)"""
        if self.direction == "Long":
            return (current_price - self.entry_price) * self.quantity
        else:  # Short
            return (self.entry_price - current_price) * self.quantity

    def get_pnl_pct(self, current_price: float) -> float:
        """ì†ìµë¥  ê³„ì‚° (ì¦ê±°ê¸ˆ ê¸°ì¤€)"""
        pnl = self.get_pnl(current_price)
        return (pnl / self.margin) * 100

    def get_roe(self, current_price: float) -> float:
        """ROE ê³„ì‚° (ë ˆë²„ë¦¬ì§€ ë°˜ì˜) - ë²„ê·¸ ìˆ˜ì • ë²„ì „"""
        # ğŸ”§ ê°€ê²© ê²€ì¦ ì¶”ê°€
        is_valid, error_msg = validate_price(current_price, self.entry_price, self.symbol)
        if not is_valid:
            print(f"âš ï¸  ê°€ê²© ê²€ì¦ ì‹¤íŒ¨ ({self.symbol}): {error_msg}")
            return 0.0  # ë¹„ì •ìƒ ë°ì´í„° ë¬´ì‹œ

        if self.direction == "Long":
            price_change_pct = (current_price / self.entry_price - 1) * 100
        else:
            price_change_pct = (1 - current_price / self.entry_price) * 100

        roe = price_change_pct * self.leverage

        # ğŸ”§ ROE ìƒí•œ/í•˜í•œ ì œí•œ
        if roe > MAX_ROE_LIMIT:
            print(
                f"âš ï¸  ROE ìƒí•œ ì´ˆê³¼ ({self.symbol}): {roe:.1f}% -> {MAX_ROE_LIMIT:.1f}% (ì§„ì…: ${self.entry_price:.4f}, í˜„ì¬: ${current_price:.4f})")
            return MAX_ROE_LIMIT
        elif roe < -MAX_ROE_LIMIT:
            print(f"âš ï¸  ROE í•˜í•œ ì´ˆê³¼ ({self.symbol}): {roe:.1f}% -> {-MAX_ROE_LIMIT:.1f}%")
            return -MAX_ROE_LIMIT

        return roe

    def get_liquidation_distance(self, current_price: float) -> float:
        """ì²­ì‚°ê°€ê¹Œì§€ ê±°ë¦¬ (%)"""
        # ğŸ”§ ê°€ê²© ê²€ì¦ ì¶”ê°€
        if current_price <= 0:
            print(f"âš ï¸  ì²­ì‚°ê±°ë¦¬ ê³„ì‚° ì‹¤íŒ¨ ({self.symbol}): Invalid price: {current_price}")
            return 0.0

        if self.direction == "Long":
            return (current_price - self.liquidation_price) / current_price * 100
        else:
            return (self.liquidation_price - current_price) / current_price * 100

    def should_close(self, current_price: float, current_time: datetime) -> tuple[bool, str]:
        """ì²­ì‚° ì—¬ë¶€ íŒë‹¨"""
        # ğŸ”§ ê°€ê²© ê²€ì¦
        is_valid, error_msg = validate_price(current_price, self.entry_price, self.symbol)
        if not is_valid:
            print(f"âš ï¸  ë¹„ì •ìƒ ê°€ê²© ê°ì§€ ({self.symbol}): {error_msg}")
            return False, ""  # ë¹„ì •ìƒ ê°€ê²©ì¼ ê²½ìš° ì²­ì‚°í•˜ì§€ ì•ŠìŒ

        # ê°•ì œ ì²­ì‚° (ë ˆë²„ë¦¬ì§€ ê³ ë ¤)
        if self.direction == "Long" and current_price <= self.liquidation_price:
            return True, "Liquidation"
        if self.direction == "Short" and current_price >= self.liquidation_price:
            return True, "Liquidation"

        # ì†ì ˆ
        if self.direction == "Long" and current_price <= self.stop_loss:
            return True, "Stop Loss"
        if self.direction == "Short" and current_price >= self.stop_loss:
            return True, "Stop Loss"

        # ìµì ˆ
        if self.direction == "Long" and current_price >= self.take_profit:
            return True, "Take Profit"
        if self.direction == "Short" and current_price <= self.take_profit:
            return True, "Take Profit"

        # ì‹œê°„ ì´ˆê³¼
        hold_minutes = (current_time - self.entry_time).total_seconds() / 60
        if hold_minutes >= MAX_HOLD_MINUTES:
            return True, "Time Limit"

        return False, ""


@dataclass
class Trade:
    """ê±°ë˜ ê¸°ë¡"""
    symbol: str
    direction: str
    entry_price: float
    exit_price: float
    quantity: float
    leverage: int
    margin: float
    entry_time: str
    exit_time: str
    pnl: float
    pnl_pct: float
    roe: float
    exit_reason: str


class Account:
    """ê³„ì¢Œ ê´€ë¦¬"""

    def __init__(self, initial_capital: float):
        self.initial_capital = initial_capital
        self.balance = initial_capital
        self.positions: Dict[str, Position] = {}
        self.trades: List[Trade] = []
        self.total_pnl = 0.0
        self.invalid_price_count = 0  # ğŸ”§ ë¹„ì •ìƒ ê°€ê²© ì¹´ìš´í„°

    def get_available_balance(self) -> float:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì”ê³  (ì¦ê±°ê¸ˆ ì°¨ê°)"""
        used_margin = sum(p.margin for p in self.positions.values())
        return self.balance - used_margin

    def get_total_value(self, prices: Dict[str, float]) -> float:
        """ì´ ìì‚° (ì”ê³  + í‰ê°€ì†ìµ)"""
        unrealized_pnl = sum(
            p.get_pnl(prices.get(p.symbol, p.entry_price))
            for p in self.positions.values()
        )
        return self.balance + unrealized_pnl

    def can_open_position(self, symbol: str) -> bool:
        """í¬ì§€ì…˜ ì§„ì… ê°€ëŠ¥ ì—¬ë¶€"""
        if symbol in self.positions:
            return False
        if len(self.positions) >= MAX_POSITIONS:
            return False
        margin_needed = self.balance * POSITION_SIZE_PCT
        if self.get_available_balance() < margin_needed:
            return False
        return True

    def open_position(self, symbol: str, direction: str, price: float):
        """í¬ì§€ì…˜ ì§„ì… (ë ˆë²„ë¦¬ì§€ ì ìš©)"""
        # ğŸ”§ ì§„ì… ê°€ê²© ê²€ì¦
        if price <= 0:
            print(f"âš ï¸  ì˜ëª»ëœ ì§„ì…ê°€ ({symbol}): ${price:.4f} - ì§„ì… ì·¨ì†Œ")
            return

        # ì¦ê±°ê¸ˆ (ì‹¤ì œ ì‚¬ìš©í•  ìê¸ˆ)
        margin = self.balance * POSITION_SIZE_PCT

        # í¬ì§€ì…˜ í¬ê¸° (ë ˆë²„ë¦¬ì§€ ì ìš©)
        position_value = margin * LEVERAGE
        quantity = position_value / price

        # ì†ì ˆ/ìµì ˆ ê°€ê²© ê³„ì‚°
        if direction == "Long":
            stop_loss = price * (1 - STOP_LOSS_PCT)
            take_profit = price * (1 + TAKE_PROFIT_PCT)
            # ì²­ì‚°ê°€ ê³„ì‚° (Long): ì§„ì…ê°€ * (1 - 1/ë ˆë²„ë¦¬ì§€ * ì²­ì‚°ë²„í¼)
            liquidation_price = price * (1 - (1 / LEVERAGE) * LIQUIDATION_BUFFER)
        else:  # Short
            stop_loss = price * (1 + STOP_LOSS_PCT)
            take_profit = price * (1 - TAKE_PROFIT_PCT)
            # ì²­ì‚°ê°€ ê³„ì‚° (Short): ì§„ì…ê°€ * (1 + 1/ë ˆë²„ë¦¬ì§€ * ì²­ì‚°ë²„í¼)
            liquidation_price = price * (1 + (1 / LEVERAGE) * LIQUIDATION_BUFFER)

        position = Position(
            symbol=symbol,
            direction=direction,
            entry_price=price,
            quantity=quantity,
            entry_time=datetime.now(),
            stop_loss=stop_loss,
            take_profit=take_profit,
            leverage=LEVERAGE,
            margin=margin,
            liquidation_price=liquidation_price
        )

        self.positions[symbol] = position
        print(f"\n{'=' * 90}")
        print(f"ğŸ”” í¬ì§€ì…˜ ì§„ì…: {symbol}")
        print(f"   ë°©í–¥: {direction}")
        print(f"   ë ˆë²„ë¦¬ì§€: {LEVERAGE}x")
        print(f"   ì§„ì…ê°€: ${price:,.4f}")
        print(f"   ìˆ˜ëŸ‰: {quantity:.4f}")
        print(f"   ì¦ê±°ê¸ˆ: ${margin:,.2f}")
        print(f"   í¬ì§€ì…˜ í¬ê¸°: ${position_value:,.2f}")
        print(f"   ì†ì ˆê°€: ${stop_loss:,.4f} (-{STOP_LOSS_PCT * 100:.1f}%)")
        print(f"   ìµì ˆê°€: ${take_profit:,.4f} (+{TAKE_PROFIT_PCT * 100:.1f}%)")
        print(f"   ì²­ì‚°ê°€: ${liquidation_price:,.4f}")
        print(f"{'=' * 90}")

    def close_position(self, symbol: str, exit_price: float, reason: str):
        """í¬ì§€ì…˜ ì²­ì‚°"""
        if symbol not in self.positions:
            return

        position = self.positions[symbol]

        # ğŸ”§ ì²­ì‚° ê°€ê²© ê²€ì¦
        is_valid, error_msg = validate_price(exit_price, position.entry_price, symbol)
        if not is_valid:
            print(f"âš ï¸  ë¹„ì •ìƒ ì²­ì‚°ê°€ ê°ì§€ ({symbol}): {error_msg}")
            print(f"    ì²­ì‚° ì·¨ì†Œ - ë‹¤ìŒ ìŠ¤ìº”ì—ì„œ ì¬ì‹œë„")
            self.invalid_price_count += 1
            return

        pnl = position.get_pnl(exit_price)
        pnl_pct = position.get_pnl_pct(exit_price)
        roe = position.get_roe(exit_price)
        roe = position.get_roe(exit_price)

        # ì”ê³  ì—…ë°ì´íŠ¸
        self.balance += pnl
        self.total_pnl += pnl

        # ê±°ë˜ ê¸°ë¡
        trade = Trade(
            symbol=symbol,
            direction=position.direction,
            entry_price=position.entry_price,
            exit_price=exit_price,
            quantity=position.quantity,
            leverage=position.leverage,
            margin=position.margin,
            entry_time=position.entry_time.strftime("%Y-%m-%d %H:%M:%S"),
            exit_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            pnl=pnl,
            pnl_pct=pnl_pct,
            roe=roe,
            exit_reason=reason
        )
        self.trades.append(trade)

        # í¬ì§€ì…˜ ì œê±°
        del self.positions[symbol]

        # ì¶œë ¥
        emoji = "ğŸ’€" if reason == "Liquidation" else ("ğŸ”´" if pnl < 0 else "ğŸŸ¢")
        print(f"\n{'=' * 90}")
        print(f"{emoji} í¬ì§€ì…˜ ì²­ì‚°: {symbol}")
        print(f"   ì‚¬ìœ : {reason}")
        print(f"   ì§„ì…ê°€: ${position.entry_price:,.4f}")
        print(f"   ì²­ì‚°ê°€: ${exit_price:,.4f}")
        print(f"   ì†ìµ: ${pnl:+,.2f} ({pnl_pct:+.2f}%)")
        print(f"   ROE: {roe:+.2f}%")
        print(f"   í˜„ì¬ ì”ê³ : ${self.balance:,.2f}")
        print(f"{'=' * 90}")

    def get_stats(self) -> Dict:
        """í†µê³„ ê³„ì‚°"""
        if not self.trades:
            return {
                "total_trades": 0,
                "wins": 0,
                "losses": 0,
                "win_rate": 0.0,
                "avg_pnl": 0.0,
                "avg_roe": 0.0,
                "max_pnl": 0.0,
                "min_pnl": 0.0,
                "max_roe": 0.0,
                "min_roe": 0.0,
                "liquidations": 0,
                "avg_win": 0.0,
                "avg_loss": 0.0
            }

        wins = [t for t in self.trades if t.pnl > 0]
        losses = [t for t in self.trades if t.pnl <= 0]
        liquidations = sum(1 for t in self.trades if t.exit_reason == "Liquidation")

        return {
            "total_trades": len(self.trades),
            "wins": len(wins),
            "losses": len(losses),
            "win_rate": (len(wins) / len(self.trades) * 100) if self.trades else 0,
            "avg_pnl": sum(t.pnl for t in self.trades) / len(self.trades),
            "avg_roe": sum(t.roe for t in self.trades) / len(self.trades),
            "max_pnl": max(t.pnl for t in self.trades),
            "min_pnl": min(t.pnl for t in self.trades),
            "max_roe": max(t.roe for t in self.trades),
            "min_roe": min(t.roe for t in self.trades),
            "liquidations": liquidations,
            "avg_win": sum(t.pnl for t in wins) / len(wins) if wins else 0,
            "avg_loss": sum(t.pnl for t in losses) / len(losses) if losses else 0,
            "invalid_prices": self.invalid_price_count  # ğŸ”§ ë¹„ì •ìƒ ê°€ê²© ì¹´ìš´íŠ¸
        }


# ===== TCN ëª¨ë¸ ì •ì˜ =====

# ===== ê¸°ì¡´ TCN ëª¨ë¸ (ë‹¨ì¼ ëª¨ë¸ìš©) =====
class Chomp1d_Basic(nn.Module):
    """ê¸°ë³¸ Chomp1d (ê¸°ì¡´ ëª¨ë¸ìš©)"""

    def __init__(self, c):
        super().__init__()
        self.c = c

    def forward(self, x):
        return x[:, :, :-self.c].contiguous() if self.c > 0 else x


def wconv(i, o, k, d):
    """Weight Normalized Convolution"""
    pad = (k - 1) * d
    return nn.utils.weight_norm(nn.Conv1d(i, o, k, padding=pad, dilation=d))


class Block(nn.Module):
    """ê¸°ë³¸ TCN Block (ê¸°ì¡´ ëª¨ë¸ìš©)"""

    def __init__(self, i, o, k, d, drop):
        super().__init__()
        self.c1 = wconv(i, o, k, d)
        self.h1 = Chomp1d_Basic((k - 1) * d)
        self.r1 = nn.ReLU()
        self.dr1 = nn.Dropout(drop)
        self.c2 = wconv(o, o, k, d)
        self.h2 = Chomp1d_Basic((k - 1) * d)
        self.r2 = nn.ReLU()
        self.dr2 = nn.Dropout(drop)
        self.ds = nn.Conv1d(i, o, 1) if i != o else None
        self.r = nn.ReLU()

    def forward(self, x):
        y = self.dr1(self.r1(self.h1(self.c1(x))))
        y = self.dr2(self.r2(self.h2(self.c2(y))))
        res = x if self.ds is None else self.ds(x)
        return self.r(y + res)


# ===== ê°œì„ ëœ TCN ëª¨ë¸ (ì•™ìƒë¸”ìš©) =====
class SqueezeExcitation(nn.Module):
    """Squeeze-and-Excitation block"""

    def __init__(self, channels, reduction=4):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels),
            nn.Sigmoid()
        )

    def forward(self, x):
        squeeze = x.mean(dim=2)
        excitation = self.fc(squeeze).unsqueeze(2)
        return x * excitation


class Chomp1d(nn.Module):
    """Chomp1d (ê°œì„ ëœ ëª¨ë¸ìš©)"""

    def __init__(self, chomp_size):
        super().__init__()
        self.chomp_size = chomp_size

    def forward(self, x):
        return x[:, :, :-self.chomp_size].contiguous() if self.chomp_size > 0 else x


class EnhancedTCNBlock(nn.Module):
    """TCN Block with SE and Layer Norm"""

    def __init__(self, in_ch, out_ch, kernel, dilation, dropout):
        super().__init__()
        padding = (kernel - 1) * dilation

        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel, dilation=dilation, padding=padding)
        self.chomp1 = Chomp1d(padding)
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(dropout)

        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel, dilation=dilation, padding=padding)
        self.chomp2 = Chomp1d(padding)
        self.relu2 = nn.ReLU()
        self.dropout2 = nn.Dropout(dropout)

        self.se = SqueezeExcitation(out_ch, reduction=4)
        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None
        self.relu = nn.ReLU()
        self.norm = nn.LayerNorm(out_ch)

    def forward(self, x):
        out = self.conv1(x)
        out = self.chomp1(out)
        out = self.relu1(out)
        out = self.dropout1(out)

        out = self.conv2(out)
        out = self.chomp2(out)
        out = self.relu2(out)
        out = self.dropout2(out)

        out = self.se(out)
        res = x if self.downsample is None else self.downsample(x)
        out = self.relu(out + res)

        out = out.transpose(1, 2)
        out = self.norm(out)
        out = out.transpose(1, 2)

        return out


class MultiHeadAttention(nn.Module):
    """Multi-Head Attention"""

    def __init__(self, hidden, num_heads, dropout):
        super().__init__()
        if hidden % num_heads != 0:
            for h in range(num_heads, 0, -1):
                if hidden % h == 0:
                    num_heads = h
                    break

        self.attn = nn.MultiheadAttention(hidden, num_heads, dropout=dropout, batch_first=True)
        self.norm = nn.LayerNorm(hidden)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        attn_out, _ = self.attn(x, x, x)
        return self.norm(x + self.dropout(attn_out))


class ImprovedTCN(nn.Module):
    """ê°œì„ ëœ TCN with SE, Attention, Uncertainty"""

    def __init__(self, in_f, hidden=64, levels=4, dropout=0.3, num_heads=4, num_classes=2):
        super().__init__()

        if hidden % num_heads != 0:
            hidden = max(num_heads, (hidden // num_heads) * num_heads)

        self.input_proj = nn.Sequential(
            nn.Linear(in_f, hidden),
            nn.LayerNorm(hidden),
            nn.ReLU(),
            nn.Dropout(dropout * 0.5)
        )

        self.tcn_blocks = nn.ModuleList()
        ch = hidden
        for i in range(levels):
            self.tcn_blocks.append(
                EnhancedTCNBlock(ch, hidden, 3, 2 ** i, dropout)
            )
            ch = hidden

        self.scale_weights = nn.Parameter(torch.ones(levels))
        self.attention = MultiHeadAttention(hidden, num_heads, dropout)

        self.fusion = nn.Sequential(
            nn.Linear(hidden * 2, hidden),
            nn.LayerNorm(hidden),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        self.classifier = nn.Sequential(
            nn.Linear(hidden, hidden // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden // 2, hidden // 4),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden // 4, num_classes)
        )

        self.uncertainty_head = nn.Sequential(
            nn.Linear(hidden, hidden // 4),
            nn.ReLU(),
            nn.Linear(hidden // 4, 1),
            nn.Sigmoid()
        )

    def forward(self, x, return_uncertainty=False):
        batch_size, seq_len, _ = x.size()

        x_proj = self.input_proj(x)

        x_tcn = x_proj.transpose(1, 2)
        tcn_features = []
        for block in self.tcn_blocks:
            x_tcn = block(x_tcn)
            tcn_features.append(x_tcn[:, :, -1])

        weights = torch.nn.functional.softmax(self.scale_weights, dim=0)
        x_tcn_fused = sum(w * f for w, f in zip(weights, tcn_features))

        x_attn = self.attention(x_proj)
        x_attn = x_attn.mean(dim=1)

        x_fused = torch.cat([x_tcn_fused, x_attn], dim=1)
        x_fused = self.fusion(x_fused)

        logits = self.classifier(x_fused)

        if return_uncertainty:
            uncertainty = self.uncertainty_head(x_fused)
            return logits, uncertainty

        return logits


class ModelEnsemble:
    """ì•™ìƒë¸” ëª¨ë¸ ë˜í¼"""

    def __init__(self, models):
        self.models = models

    def predict(self, x, use_tta=False, n_tta=5):
        """ì•™ìƒë¸” ì˜ˆì¸¡"""
        device = x.device
        all_preds = []

        for model in self.models:
            model.eval()
            with torch.no_grad():
                if use_tta:
                    tta_preds = []
                    for _ in range(n_tta):
                        noise = torch.randn_like(x) * 0.01
                        pred = model(x + noise)
                        tta_preds.append(torch.softmax(pred, dim=1))
                    pred = torch.stack(tta_preds).mean(0)
                else:
                    pred = torch.softmax(model(x), dim=1)
                all_preds.append(pred)

        # í‰ê· 
        ensemble_pred = torch.stack(all_preds).mean(0)

        # ë¶ˆí™•ì‹¤ì„± (í‘œì¤€í¸ì°¨)
        uncertainty = torch.stack(all_preds).std(0).max(1)[0]

        return ensemble_pred, uncertainty


# ===== ëª¨ë¸ ë¡œë“œ =====
print("\nğŸ¤– ì‹¬ë³¼ë³„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
MODELS = {}
MODEL_CONFIGS = {}

for symbol in SYMBOLS:
    symbol = symbol.strip()
    if symbol not in MODEL_PATHS:
        print(f"âš ï¸  {symbol}: ëª¨ë¸ ê²½ë¡œ ë¯¸ì„¤ì •")
        continue

    model_path_or_dir = MODEL_PATHS[symbol]

    # ë””ë ‰í† ë¦¬ì¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸
    if os.path.isdir(model_path_or_dir):
        # ===== ë””ë ‰í† ë¦¬ - ì•™ìƒë¸” ë°©ì‹ =====
        model_dir = model_path_or_dir
        meta_path = os.path.join(model_dir, "meta.json")

        if not os.path.exists(meta_path):
            print(f"âŒ {symbol}: meta.json íŒŒì¼ ì—†ìŒ - {meta_path}")
            continue

        try:
            with open(meta_path, 'r') as f:
                meta = json.load(f)

            feat_cols = meta['feat_cols']
            seq_len = meta['seq_len']
            scaler_mu = np.array(meta['scaler_mu'], dtype=np.float32)
            scaler_sd = np.array(meta['scaler_sd'], dtype=np.float32)
            n_models = meta['n_models']
            hidden = meta['hidden']
            levels = meta['levels']
            dropout = meta['dropout']
            num_classes = 2  # train_tcn_improved.pyëŠ” 2-class

            # ì•™ìƒë¸” ëª¨ë¸ë“¤ ë¡œë“œ
            models = []
            for i in range(n_models):
                model_file = os.path.join(model_dir, f"model_{i + 1}.pt")
                if not os.path.exists(model_file):
                    print(f"âš ï¸  {symbol}: ëª¨ë¸ íŒŒì¼ ì—†ìŒ - {model_file}")
                    continue

                # ê° ëª¨ë¸ì˜ ì‹¤ì œ hidden size ì¶”ì¶œ
                state_dict = torch.load(model_file, map_location="cpu", weights_only=True)

                if 'input_proj.0.weight' in state_dict:
                    actual_hidden = state_dict['input_proj.0.weight'].shape[0]
                else:
                    print(f"âŒ {symbol} model_{i + 1}: ë¡œë“œ ì‹¤íŒ¨")
                    continue

                model = ImprovedTCN(
                    in_f=len(feat_cols),
                    hidden=actual_hidden,  # â† ì‹¤ì œ ê°’ ì‚¬ìš©!
                    levels=levels,
                    dropout=dropout,
                    num_heads=4,
                    num_classes=num_classes
                )
                model.load_state_dict(torch.load(model_file, map_location="cpu", weights_only=True))
                model.eval()
                models.append(model)

            if len(models) == 0:
                print(f"âŒ {symbol}: ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                continue

            # ì•™ìƒë¸” ë˜í¼
            ensemble = ModelEnsemble(models)

            MODELS[symbol] = ensemble
            MODEL_CONFIGS[symbol] = {
                'feat_cols': feat_cols,
                'seq_len': seq_len,
                'scaler_mu': scaler_mu,
                'scaler_sd': scaler_sd,
                'is_single_task': True,
                'num_classes': num_classes,
                'is_ensemble': True,
                'n_models': len(models)
            }

            print(f"âœ… {symbol}: ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ "
                  f"({len(models)}ê°œ ëª¨ë¸, {num_classes}-class, levels={levels}, hidden={hidden})")

        except Exception as e:
            import traceback

            print(f"âŒ {symbol}: ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - {e}")
            if DEBUG_MODE:
                traceback.print_exc()

    elif os.path.isfile(model_path_or_dir):
        # ===== íŒŒì¼ - ê¸°ì¡´ ë‹¨ì¼ ëª¨ë¸ ë°©ì‹ =====
        model_path = model_path_or_dir

        try:
            checkpoint = torch.load(model_path, map_location="cpu", weights_only=False)
            feat_cols = checkpoint['feat_cols']
            meta = checkpoint.get('meta', {})
            seq_len = meta.get('seq_len', 60)
            scaler_mu = checkpoint.get('scaler_mu')
            scaler_sd = checkpoint.get('scaler_sd')

            model_dict = checkpoint['model']

            # ëª¨ë¸ êµ¬ì¡° ê°ì§€
            max_layer = max(
                [int(k.split('.')[1]) for k in model_dict.keys()
                 if k.startswith('tcn.') and len(k.split('.')) > 2],
                default=0)
            levels = max_layer + 1
            hidden = model_dict['tcn.0.c1.weight_v'].shape[0] if 'tcn.0.c1.weight_v' in model_dict else 32
            k = model_dict['tcn.0.c1.weight_v'].shape[2] if 'tcn.0.c1.weight_v' in model_dict else 3
            drop = meta.get('dropout', 0.2)

            # ëª¨ë¸ íƒ€ì… ë° í´ë˜ìŠ¤ ìˆ˜ ê°ì§€
            if 'head.weight' in model_dict:
                # Single-task ëª¨ë¸
                num_classes = model_dict['head.weight'].shape[0]


                class TCN_SingleTask(nn.Module):
                    def __init__(self, in_f, hidden, levels, k, drop, num_classes):
                        super().__init__()
                        L = []
                        ch = in_f
                        for i in range(levels):
                            L.append(Block(ch, hidden, k, 2 ** i, drop))
                            ch = hidden
                        self.tcn = nn.Sequential(*L)
                        self.head = nn.Linear(hidden, num_classes)

                    def forward(self, X):
                        X = X.transpose(1, 2)
                        H = self.tcn(X)[:, :, -1]
                        return self.head(H)


                model = TCN_SingleTask(len(feat_cols), hidden, levels, k, drop, num_classes)

            elif 'head_cls.weight' in model_dict:
                # Multi-task ëª¨ë¸
                num_classes = model_dict['head_cls.weight'].shape[0]


                class TCN_MT(nn.Module):
                    def __init__(self, in_f, hidden, levels, k, drop, num_classes):
                        super().__init__()
                        L = []
                        ch = in_f
                        for i in range(levels):
                            L.append(Block(ch, hidden, k, 2 ** i, drop))
                            ch = hidden
                        self.tcn = nn.Sequential(*L)
                        self.head_cls = nn.Linear(hidden, num_classes)
                        self.head_ttt = nn.Linear(hidden, 1)

                    def forward(self, X):
                        X = X.transpose(1, 2)
                        H = self.tcn(X)[:, :, -1]
                        return self.head_cls(H), self.head_ttt(H)


                model = TCN_MT(len(feat_cols), hidden, levels, k, drop, num_classes)
            else:
                # ê¸°ë³¸ê°’ (3-class Multi-task)
                num_classes = 3


                class TCN_MT(nn.Module):
                    def __init__(self, in_f, hidden, levels, k, drop):
                        super().__init__()
                        L = []
                        ch = in_f
                        for i in range(levels):
                            L.append(Block(ch, hidden, k, 2 ** i, drop))
                            ch = hidden
                        self.tcn = nn.Sequential(*L)
                        self.head_cls = nn.Linear(hidden, 3)
                        self.head_ttt = nn.Linear(hidden, 1)

                    def forward(self, X):
                        X = X.transpose(1, 2)
                        H = self.tcn(X)[:, :, -1]
                        return self.head_cls(H), self.head_ttt(H)


                model = TCN_MT(len(feat_cols), hidden, levels, k, drop)

            model.load_state_dict(model_dict)
            model.eval()

            MODELS[symbol] = model
            MODEL_CONFIGS[symbol] = {
                'feat_cols': feat_cols,
                'seq_len': seq_len,
                'scaler_mu': scaler_mu,
                'scaler_sd': scaler_sd,
                'is_single_task': 'head.weight' in model_dict,
                'num_classes': num_classes,
                'is_ensemble': False
            }

            class_type = f"{num_classes}-class"
            task_type = 'Single-task' if MODEL_CONFIGS[symbol]['is_single_task'] else 'Multi-task'
            print(f"âœ… {symbol}: {task_type} {class_type} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ "
                  f"(levels={levels}, hidden={hidden}, k={k})")

        except Exception as e:
            import traceback

            print(f"âŒ {symbol}: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - {e}")
            if DEBUG_MODE:
                traceback.print_exc()

    else:
        print(f"âŒ {symbol}: ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ - {model_path_or_dir}")
        print(f"   ë””ë ‰í† ë¦¬ ì¡´ì¬: {os.path.isdir(model_path_or_dir)}")
        print(f"   íŒŒì¼ ì¡´ì¬: {os.path.isfile(model_path_or_dir)}")

if not MODELS:
    print("\nâŒ ERROR: ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
    print("í™•ì¸ ì‚¬í•­:")
    print("   1. MODEL_PATHSì— ì‹¬ë³¼ë³„ ëª¨ë¸ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
    print("   2. ëª¨ë¸ íŒŒì¼/ë””ë ‰í† ë¦¬ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
    print("   3. SYMBOLS í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ëœ ì‹¬ë³¼ê³¼ MODEL_PATHSì˜ í‚¤ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸")
    print(f"\ní˜„ì¬ ì„¤ì •:")
    print(f"   SYMBOLS í™˜ê²½ë³€ìˆ˜: {SYMBOLS_ENV if SYMBOLS_ENV else '(ë¯¸ì„¤ì • - ëª¨ë“  ëª¨ë¸ ì‚¬ìš©)'}")
    print(f"   ì‹œë„í•œ ì‹¬ë³¼: {', '.join(SYMBOLS)}")
    print(f"   MODEL_PATHSì— ìˆëŠ” ì‹¬ë³¼: {', '.join(MODEL_PATHS.keys())}")
    exit(1)

print(f"\nâœ… ì´ {len(MODELS)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
print(f"   ì‚¬ìš© ê°€ëŠ¥ ì‹¬ë³¼: {', '.join(MODELS.keys())}")

# í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ëœ ì‹¬ë³¼ ì¤‘ ë¡œë“œ ì‹¤íŒ¨í•œ ê²ƒë“¤ ì•ˆë‚´
failed_symbols = [s for s in SYMBOLS if s not in MODELS]
if failed_symbols:
    print(f"\nâš ï¸  ë¡œë“œ ì‹¤íŒ¨í•œ ì‹¬ë³¼ ({len(failed_symbols)}ê°œ): {', '.join(failed_symbols)}")

# ===== ëª¨ë¸ ë¡œë“œ (ì•™ìƒë¸” ê° ëª¨ë¸ì˜ hidden size ìë™ ì¶”ì¶œ) =====
print("\nğŸ¤– ì‹¬ë³¼ë³„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
MODELS = {}
MODEL_CONFIGS = {}

for symbol in SYMBOLS:
    symbol = symbol.strip()
    if symbol not in MODEL_PATHS:
        print(f"âš ï¸  {symbol}: ëª¨ë¸ ê²½ë¡œ ë¯¸ì„¤ì •")
        continue

    model_path_or_dir = MODEL_PATHS[symbol]

    # ë””ë ‰í† ë¦¬ì¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸
    if os.path.isdir(model_path_or_dir):
        # ===== ë””ë ‰í† ë¦¬ - ì•™ìƒë¸” ë°©ì‹ =====
        model_dir = model_path_or_dir
        meta_path = os.path.join(model_dir, "meta.json")

        if not os.path.exists(meta_path):
            print(f"âŒ {symbol}: meta.json íŒŒì¼ ì—†ìŒ - {meta_path}")
            continue

        try:
            with open(meta_path, 'r') as f:
                meta = json.load(f)

            feat_cols = meta['feat_cols']
            seq_len = meta['seq_len']
            scaler_mu = np.array(meta['scaler_mu'], dtype=np.float32)
            scaler_sd = np.array(meta['scaler_sd'], dtype=np.float32)
            n_models = meta['n_models']
            # hiddenì€ metaì—ì„œ ì½ì§€ ì•ŠìŒ - ê° ëª¨ë¸ì—ì„œ ì¶”ì¶œ
            levels = meta['levels']
            dropout = meta['dropout']
            num_classes = 2  # train_tcn_improved.pyëŠ” 2-class

            # âœ… ì•™ìƒë¸” ëª¨ë¸ë“¤ ë¡œë“œ (ê° ëª¨ë¸ì˜ hidden size ìë™ ì¶”ì¶œ)
            models = []
            for i in range(n_models):
                model_file = os.path.join(model_dir, f"model_{i + 1}.pt")
                if not os.path.exists(model_file):
                    print(f"âš ï¸  {symbol}: ëª¨ë¸ íŒŒì¼ ì—†ìŒ - {model_file}")
                    continue

                # ğŸ”§ ê° ëª¨ë¸ íŒŒì¼ì—ì„œ ì‹¤ì œ hidden size ì¶”ì¶œ
                state_dict = torch.load(model_file, map_location="cpu", weights_only=True)

                if 'input_proj.0.weight' in state_dict:
                    actual_hidden, actual_in_features = state_dict['input_proj.0.weight'].shape

                    # Feature ê°œìˆ˜ ê²€ì¦
                    if actual_in_features != len(feat_cols):
                        print(f"âš ï¸  {symbol} model_{i + 1}.pt: Feature ê°œìˆ˜ ë¶ˆì¼ì¹˜ "
                              f"(ëª¨ë¸={actual_in_features}, meta={len(feat_cols)})")
                        continue

                    if DEBUG_MODE:
                        print(f"   ğŸ“Š model_{i + 1}.pt: hidden={actual_hidden}, features={actual_in_features}")
                else:
                    print(f"âŒ {symbol} model_{i + 1}.pt: input_proj.0.weight ì—†ìŒ")
                    continue

                # ì‹¤ì œ hidden sizeë¡œ ëª¨ë¸ ìƒì„±
                model = ImprovedTCN(
                    in_f=len(feat_cols),
                    hidden=actual_hidden,  # âœ… ì‹¤ì œ ê°’ ì‚¬ìš©!
                    levels=levels,
                    dropout=dropout,
                    num_heads=4,
                    num_classes=num_classes
                )
                model.load_state_dict(state_dict)
                model.eval()
                models.append(model)

            if len(models) == 0:
                print(f"âŒ {symbol}: ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                continue

            # ì•™ìƒë¸” ë˜í¼
            ensemble = ModelEnsemble(models)

            MODELS[symbol] = ensemble
            MODEL_CONFIGS[symbol] = {
                'feat_cols': feat_cols,
                'seq_len': seq_len,
                'scaler_mu': scaler_mu,
                'scaler_sd': scaler_sd,
                'is_single_task': True,
                'num_classes': num_classes,
                'is_ensemble': True,
                'n_models': len(models)
            }

            print(f"âœ… {symbol}: ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ "
                  f"({len(models)}ê°œ ëª¨ë¸, {num_classes}-class, levels={levels})")

        except Exception as e:
            import traceback

            print(f"âŒ {symbol}: ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - {e}")
            if DEBUG_MODE:
                traceback.print_exc()

    elif os.path.isfile(model_path_or_dir):
        # ===== íŒŒì¼ - ê¸°ì¡´ ë‹¨ì¼ ëª¨ë¸ ë°©ì‹ =====
        model_path = model_path_or_dir

        try:
            checkpoint = torch.load(model_path, map_location="cpu", weights_only=False)
            feat_cols = checkpoint['feat_cols']
            meta = checkpoint.get('meta', {})
            seq_len = meta.get('seq_len', 60)
            scaler_mu = checkpoint.get('scaler_mu')
            scaler_sd = checkpoint.get('scaler_sd')

            model_dict = checkpoint['model']

            # ëª¨ë¸ êµ¬ì¡° ê°ì§€
            max_layer = max(
                [int(k.split('.')[1]) for k in model_dict.keys()
                 if k.startswith('tcn.') and len(k.split('.')) > 2],
                default=0)
            levels = max_layer + 1
            hidden = model_dict['tcn.0.c1.weight_v'].shape[0] if 'tcn.0.c1.weight_v' in model_dict else 32
            k = model_dict['tcn.0.c1.weight_v'].shape[2] if 'tcn.0.c1.weight_v' in model_dict else 3
            drop = meta.get('dropout', 0.2)

            # ëª¨ë¸ íƒ€ì… ë° í´ë˜ìŠ¤ ìˆ˜ ê°ì§€
            if 'head.weight' in model_dict:
                # Single-task ëª¨ë¸
                num_classes = model_dict['head.weight'].shape[0]


                class TCN_SingleTask(nn.Module):
                    def __init__(self, in_f, hidden, levels, k, drop, num_classes):
                        super().__init__()
                        L = []
                        ch = in_f
                        for i in range(levels):
                            L.append(Block(ch, hidden, k, 2 ** i, drop))
                            ch = hidden
                        self.tcn = nn.Sequential(*L)
                        self.head = nn.Linear(hidden, num_classes)

                    def forward(self, X):
                        X = X.transpose(1, 2)
                        H = self.tcn(X)[:, :, -1]
                        return self.head(H)


                model = TCN_SingleTask(len(feat_cols), hidden, levels, k, drop, num_classes)

            elif 'head_cls.weight' in model_dict:
                # Multi-task ëª¨ë¸
                num_classes = model_dict['head_cls.weight'].shape[0]


                class TCN_MT(nn.Module):
                    def __init__(self, in_f, hidden, levels, k, drop, num_classes):
                        super().__init__()
                        L = []
                        ch = in_f
                        for i in range(levels):
                            L.append(Block(ch, hidden, k, 2 ** i, drop))
                            ch = hidden
                        self.tcn = nn.Sequential(*L)
                        self.head_cls = nn.Linear(hidden, num_classes)
                        self.head_ttt = nn.Linear(hidden, 1)

                    def forward(self, X):
                        X = X.transpose(1, 2)
                        H = self.tcn(X)[:, :, -1]
                        return self.head_cls(H), self.head_ttt(H)


                model = TCN_MT(len(feat_cols), hidden, levels, k, drop, num_classes)
            else:
                # ê¸°ë³¸ê°’ (3-class Multi-task)
                num_classes = 3


                class TCN_MT(nn.Module):
                    def __init__(self, in_f, hidden, levels, k, drop):
                        super().__init__()
                        L = []
                        ch = in_f
                        for i in range(levels):
                            L.append(Block(ch, hidden, k, 2 ** i, drop))
                            ch = hidden
                        self.tcn = nn.Sequential(*L)
                        self.head_cls = nn.Linear(hidden, 3)
                        self.head_ttt = nn.Linear(hidden, 1)

                    def forward(self, X):
                        X = X.transpose(1, 2)
                        H = self.tcn(X)[:, :, -1]
                        return self.head_cls(H), self.head_ttt(H)


                model = TCN_MT(len(feat_cols), hidden, levels, k, drop)

            model.load_state_dict(model_dict)
            model.eval()

            MODELS[symbol] = model
            MODEL_CONFIGS[symbol] = {
                'feat_cols': feat_cols,
                'seq_len': seq_len,
                'scaler_mu': scaler_mu,
                'scaler_sd': scaler_sd,
                'is_single_task': 'head.weight' in model_dict,
                'num_classes': num_classes,
                'is_ensemble': False
            }

            class_type = f"{num_classes}-class"
            task_type = 'Single-task' if MODEL_CONFIGS[symbol]['is_single_task'] else 'Multi-task'
            print(f"âœ… {symbol}: {task_type} {class_type} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ "
                  f"(levels={levels}, hidden={hidden}, k={k})")

        except Exception as e:
            import traceback

            print(f"âŒ {symbol}: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - {e}")
            if DEBUG_MODE:
                traceback.print_exc()

    else:
        print(f"âŒ {symbol}: ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ - {model_path_or_dir}")
        print(f"   ë””ë ‰í† ë¦¬ ì¡´ì¬: {os.path.isdir(model_path_or_dir)}")
        print(f"   íŒŒì¼ ì¡´ì¬: {os.path.isfile(model_path_or_dir)}")

if not MODELS:
    print("\nâŒ ERROR: ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
    print("í™•ì¸ ì‚¬í•­:")
    print("   1. MODEL_PATHSì— ì‹¬ë³¼ë³„ ëª¨ë¸ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
    print("   2. ëª¨ë¸ íŒŒì¼/ë””ë ‰í† ë¦¬ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
    print("   3. SYMBOLS í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ëœ ì‹¬ë³¼ê³¼ MODEL_PATHSì˜ í‚¤ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸")
    print(f"\ní˜„ì¬ ì„¤ì •:")
    print(f"   SYMBOLS í™˜ê²½ë³€ìˆ˜: {SYMBOLS_ENV if SYMBOLS_ENV else '(ë¯¸ì„¤ì • - ëª¨ë“  ëª¨ë¸ ì‚¬ìš©)'}")
    print(f"   ì‹œë„í•œ ì‹¬ë³¼: {', '.join(SYMBOLS)}")
    print(f"   MODEL_PATHSì— ìˆëŠ” ì‹¬ë³¼: {', '.join(MODEL_PATHS.keys())}")
    exit(1)

print(f"\nâœ… ì´ {len(MODELS)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
print(f"   ì‚¬ìš© ê°€ëŠ¥ ì‹¬ë³¼: {', '.join(MODELS.keys())}")

# í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ëœ ì‹¬ë³¼ ì¤‘ ë¡œë“œ ì‹¤íŒ¨í•œ ê²ƒë“¤ ì•ˆë‚´
failed_symbols = [s for s in SYMBOLS if s not in MODELS]
if failed_symbols:
    print(f"\nâš ï¸  ë¡œë“œ ì‹¤íŒ¨í•œ ì‹¬ë³¼ ({len(failed_symbols)}ê°œ): {', '.join(failed_symbols)}")


# ===== API í´ë˜ìŠ¤ =====
class BybitAPI:
    """Bybit API í´ë¼ì´ì–¸íŠ¸ (ê³µí†µ)"""

    def __init__(self):
        self.base_url = "https://api-testnet.bybit.com" if USE_TESTNET else "https://api.bybit.com"

    def get_ticker(self, symbol: str) -> dict:
        """í˜„ì¬ ê°€ê²© ì¡°íšŒ"""
        try:
            url = f"{self.base_url}/v5/market/tickers"
            params = {"category": "linear", "symbol": symbol}
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()

            if data.get("retCode") == 0 and data.get("result", {}).get("list"):
                return data
            return {}
        except Exception as e:
            print(f"âš ï¸  Ticker ì¡°íšŒ ì‹¤íŒ¨ ({symbol}): {e}")
            return {}

    def get_klines(self, symbol: str, interval: str = "5", limit: int = 200) -> pd.DataFrame:
        """ê³¼ê±° ë°ì´í„° ì¡°íšŒ"""
        try:
            url = f"{self.base_url}/v5/market/kline"
            params = {
                "category": "linear",
                "symbol": symbol,
                "interval": interval,
                "limit": limit
            }
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()

            ret_code = data.get("retCode", -1)
            if ret_code != 0:
                print(f"âš ï¸  API Error for {symbol}: retCode={ret_code}, msg={data.get('retMsg', 'Unknown')}")
                return pd.DataFrame()

            if data.get("retCode") == 0:
                klines = data["result"]["list"]
                if not klines:
                    print(f"âš ï¸  {symbol}: API returned empty klines list")
                    return pd.DataFrame()

                df = pd.DataFrame(klines,
                                  columns=["timestamp", "open", "high", "low", "close", "volume", "turnover"])
                df = df.astype({
                    "open": float, "high": float, "low": float, "close": float, "volume": float
                })
                df["timestamp"] = pd.to_datetime(df["timestamp"].astype(int), unit='ms')
                df = df.sort_values("timestamp").reset_index(drop=True)
                return df
            return pd.DataFrame()
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸  ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ({symbol}): {e}")
            return pd.DataFrame()
        except Exception as e:
            print(f"âš ï¸  Klines ì¡°íšŒ ì‹¤íŒ¨ ({symbol}): {type(e).__name__}: {e}")
            return pd.DataFrame()


API = BybitAPI()


# ===== íŠ¹ì„± ìƒì„± (train_tcn_improved.pyì™€ ì™„ì „ ì¼ì¹˜) =====
def calculate_rsi(series, period=14):
    """RSI ê³„ì‚°"""
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / (loss + 1e-8)
    rsi = 100 - (100 / (1 + rs))
    return rsi.fillna(50)


def calculate_macd(series, fast=12, slow=26, signal=9):
    """MACD ê³„ì‚°"""
    ema_fast = series.ewm(span=fast, adjust=False).mean()
    ema_slow = series.ewm(span=slow, adjust=False).mean()
    macd = ema_fast - ema_slow
    macd_signal = macd.ewm(span=signal, adjust=False).mean()
    return (macd - macd_signal).fillna(0)


def generate_features(df: pd.DataFrame, feat_cols: list) -> pd.DataFrame:
    """
    train_tcn_improved.pyì˜ add_advanced_featuresì™€ ì™„ì „íˆ ë™ì¼í•œ ë¡œì§
    """
    g = df.copy()

    # symbol ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€ (ë‹¨ì¼ ì‹¬ë³¼ ì²˜ë¦¬)
    if 'symbol' not in g.columns:
        g['symbol'] = 'TEMP'

    # date ì»¬ëŸ¼ ì²˜ë¦¬
    if 'date' not in g.columns and 'timestamp' in g.columns:
        g['date'] = pd.to_datetime(g['timestamp'])
    elif 'date' in g.columns:
        g['date'] = pd.to_datetime(g['date'])
    else:
        g['date'] = pd.to_datetime(df.index)

    g = g.sort_values(["symbol", "date"]).reset_index(drop=True)

    # ===== 1. ê¸°ë³¸ ìˆ˜ìµë¥  =====
    g["logc"] = np.log(np.clip(g["close"].values, 1e-12, None))
    g["ret1"] = g.groupby("symbol")["logc"].diff().fillna(0.0)

    # ===== 2. ì‹œì¥ ë¯¸ì„¸êµ¬ì¡° =====
    g['spread'] = (g['high'] - g['low']) / (g['close'] + 1e-8)
    g['body_ratio'] = np.abs(g['close'] - g['open']) / (g['high'] - g['low'] + 1e-8)
    g['upper_shadow'] = (g['high'] - np.maximum(g['open'], g['close'])) / (g['high'] - g['low'] + 1e-8)
    g['lower_shadow'] = (np.minimum(g['open'], g['close']) - g['low']) / (g['high'] - g['low'] + 1e-8)

    # ===== 3. ë³€ë™ì„± (ë‹¤ì¤‘ ì‹œê°„ëŒ€) =====
    for w in (6, 12, 24, 72, 144):
        g[f"rv{w}"] = g.groupby("symbol")["ret1"].transform(
            lambda s: s.rolling(w, min_periods=max(2, w // 3)).std()
        ).fillna(0.0)

    # ===== 4. ê³ ê¸‰ ëª¨ë©˜í…€ =====
    for w in (6, 12, 24, 72):
        # EMA ê¸°ë°˜ ëª¨ë©˜í…€
        ema = g.groupby("symbol")["close"].transform(
            lambda s: s.ewm(span=w, adjust=False).mean()
        )
        g[f"mom{w}"] = (g["close"] / (ema + 1e-8) - 1.0).fillna(0.0)

        # RSI
        g[f"rsi{w}"] = g.groupby("symbol")["close"].transform(
            lambda s: calculate_rsi(s, w)
        ) / 100.0 - 0.5  # Normalize to [-0.5, 0.5]

    # MACD
    for w in (12, 24):
        g[f"macd{w}"] = g.groupby("symbol")["close"].transform(
            lambda s: calculate_macd(s, fast=w, slow=w * 2, signal=w // 2)
        ) / (g["close"] + 1e-8)

    # ===== 5. ë³¼ë¥¨ í”„ë¡œíŒŒì¼ =====
    # Z-score
    for w in (12, 24, 72):
        mu = g.groupby("symbol")["volume"].transform(
            lambda s: s.rolling(w, min_periods=max(2, w // 3)).mean()
        )
        sd = g.groupby("symbol")["volume"].transform(
            lambda s: s.rolling(w, min_periods=max(2, w // 3)).std()
        ).replace(0, 1.0)
        g[f"vz{w}"] = ((g["volume"] - mu) / sd).fillna(0.0)

    # VWAP
    g["vwap_num"] = (g["close"] * g["volume"]).groupby(g["symbol"]).transform(
        lambda s: s.rolling(20, min_periods=10).sum()
    )
    g["vwap_den"] = g.groupby("symbol")["volume"].transform(
        lambda s: s.rolling(20, min_periods=10).sum()
    )
    g["vwap20"] = g["vwap_num"] / (g["vwap_den"] + 1e-8)
    g["vwap_dist"] = (g["close"] - g["vwap20"]) / (g["vwap20"] + 1e-8)
    g = g.drop(["vwap_num", "vwap_den"], axis=1)

    # ë§¤ìˆ˜/ë§¤ë„ ì••ë ¥
    g['buy_pressure'] = np.where(g['close'] > g['open'], g['volume'], 0)
    g['sell_pressure'] = np.where(g['close'] < g['open'], g['volume'], 0)

    for w in (12, 24):
        buy_vol = g.groupby("symbol")['buy_pressure'].transform(lambda s: s.rolling(w).sum())
        sell_vol = g.groupby("symbol")['sell_pressure'].transform(lambda s: s.rolling(w).sum())
        g[f'pressure_ratio{w}'] = (buy_vol - sell_vol) / (buy_vol + sell_vol + 1e-8)

    # ê±°ë˜ëŸ‰ ê¸‰ë“±
    g["vol_spike"] = g.groupby("symbol")["volume"].transform(
        lambda s: s / (s.shift(1) + 1e-8) - 1.0
    ).fillna(0.0)

    # ===== 6. ê°€ê²© íŒ¨í„´ =====
    g["hl_ratio"] = (g["high"] - g["low"]) / (g["close"] + 1e-8)
    g["co_ratio"] = (g["close"] - g["open"]) / (g["open"] + 1e-8)

    # ì—°ì† ìƒìŠ¹/í•˜ë½
    g["up_streak"] = g.groupby("symbol")["ret1"].transform(
        lambda s: (s > 0).astype(int).groupby((s <= 0).cumsum()).cumsum()
    )
    g["down_streak"] = g.groupby("symbol")["ret1"].transform(
        lambda s: (s < 0).astype(int).groupby((s >= 0).cumsum()).cumsum()
    )

    # ===== 7. ë³€ë™ì„± ë ˆì§ =====
    g['vol_regime'] = g.groupby("symbol")['rv24'].transform(
        lambda s: pd.qcut(s.fillna(s.median()), q=5, labels=False, duplicates='drop')
    ).fillna(2).astype(float) / 4.0  # Normalize to [0, 1]

    # ===== 8. ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ =====
    g['hour'] = g['date'].dt.hour / 23.0  # Normalize
    g['day_of_week'] = g['date'].dt.dayofweek / 6.0
    g['is_market_hours'] = g['date'].dt.hour.between(9, 16).astype(float)

    # ===== 9. í¬ë¡œìŠ¤ì˜¤ë²„ ì‹ í˜¸ =====
    for w1, w2 in [(6, 12), (12, 24), (24, 72)]:
        ema1 = g.groupby("symbol")["close"].transform(lambda s: s.ewm(span=w1).mean())
        ema2 = g.groupby("symbol")["close"].transform(lambda s: s.ewm(span=w2).mean())
        g[f"cross_{w1}_{w2}"] = (ema1 - ema2) / (ema2 + 1e-8)

    # ===== 10. ATR (Average True Range) =====
    g['tr'] = np.maximum(
        g['high'] - g['low'],
        np.maximum(
            np.abs(g['high'] - g['close'].shift(1)),
            np.abs(g['low'] - g['close'].shift(1))
        )
    )
    for w in (12, 24):
        g[f'atr{w}'] = g.groupby("symbol")['tr'].transform(
            lambda s: s.rolling(w).mean()
        ) / (g['close'] + 1e-8)

    # ATR í‰ê·  (trì˜ rolling meanì´ atr)
    g['atr'] = g.groupby("symbol")['tr'].transform(
        lambda s: s.rolling(14).mean()
    ) / (g['close'] + 1e-8)

    # NaN ì²˜ë¦¬
    for col in g.columns:
        if col not in ["symbol", "date", "timestamp", "open", "high", "low", "close", "volume", "turnover"]:
            g[col] = g[col].fillna(0.0)
            # Clip extreme values
            g[col] = g[col].clip(-10, 10)

    # íŠ¹ì„± ë¦¬ìŠ¤íŠ¸ ìˆœì„œëŒ€ë¡œ ë°˜í™˜
    return g[feat_cols]


# ===== ì¶”ë¡  í•¨ìˆ˜ (ì‹¬ë³¼ë³„ ëª¨ë¸ ì‚¬ìš©) =====
def predict(symbol: str, debug: bool = False) -> dict:
    """âœ… ì‹¬ë³¼ë³„ ëª¨ë¸ë¡œ ì¶”ë¡ """
    symbol = symbol.strip()

    # í•´ë‹¹ ì‹¬ë³¼ì˜ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
    if symbol not in MODELS:
        return {
            "error": f"No model for {symbol}",
            "symbol": symbol
        }

    model = MODELS[symbol]
    config = MODEL_CONFIGS[symbol]

    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ë™ì ìœ¼ë¡œ í•„ìš”í•œ ë§Œí¼ ìš”ì²­)
    # seq_len + ìµœëŒ€ window(120) + ì—¬ìœ (40) = ì¶©ë¶„í•œ ë°ì´í„°
    max_window = 120  # rv120, mom120, vz120 ë“±ì—ì„œ ì‚¬ìš©
    required_length = config['seq_len'] + max_window + 40
    limit = max(200, min(required_length, 1000))  # ìµœì†Œ 200, ìµœëŒ€ 1000
    df = API.get_klines(symbol, interval="5", limit=limit)

    if debug:
        print(f"\n[DEBUG {symbol}] ë°ì´í„° ì¡°íšŒ ê²°ê³¼:")
        print(f"  - ìš”ì²­í•œ limit: {limit}")
        print(f"  - df.empty: {df.empty}")
        print(f"  - len(df): {len(df) if not df.empty else 0}")
        print(f"  - í•„ìš”í•œ ê¸¸ì´: {config['seq_len'] + 20}")
        print(f"  - seq_len: {config['seq_len']}")
        if not df.empty:
            print(f"  - df.columns: {df.columns.tolist()}")
            print(f"  - df.head(2):\n{df.head(2)}")

    if df.empty:
        return {
            "error": "API returned empty data",
            "symbol": symbol
        }

    if len(df) < config['seq_len'] + 20:
        return {
            "error": f"Insufficient data (got {len(df)}, need {config['seq_len'] + 20})",
            "symbol": symbol
        }

    # íŠ¹ì„± ìƒì„±
    df_feat = generate_features(df, config['feat_cols'])
    df_feat = df_feat.dropna()

    if debug:
        print(f"\n[DEBUG {symbol}] íŠ¹ì„± ìƒì„± ê²°ê³¼:")
        print(f"  - ìš”êµ¬ë˜ëŠ” íŠ¹ì„± ìˆ˜: {len(config['feat_cols'])}")
        print(f"  - ì‹¤ì œ ìƒì„±ëœ íŠ¹ì„± ìˆ˜: {len(df_feat.columns)}")
        print(f"  - ìƒì„±ëœ íŠ¹ì„±: {df_feat.columns.tolist()}")
        print(f"  - ìš”êµ¬ë˜ëŠ” íŠ¹ì„± (ì²˜ìŒ 10ê°œ): {config['feat_cols'][:10]}")

        # ëˆ„ë½ëœ íŠ¹ì„± í™•ì¸
        missing_cols = [c for c in config['feat_cols'] if c not in df_feat.columns]
        if missing_cols:
            print(f"  - âš ï¸ ëˆ„ë½ëœ íŠ¹ì„± ({len(missing_cols)}ê°œ): {missing_cols[:20]}")

        # âœ… íŠ¹ì„± ê°’ ë²”ìœ„ í™•ì¸
        print(f"\n[DEBUG {symbol}] íŠ¹ì„± ê°’ í†µê³„ (ìµœê·¼ ë°ì´í„°):")
        print(f"  - NaN ê°œìˆ˜: {df_feat.isna().sum().sum()}")
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ì•ˆì „í•˜ê²Œ ì²´í¬
        try:
            numeric_df = df_feat.select_dtypes(include=[np.number])
            if len(numeric_df.columns) > 0:
                print(f"  - Inf ê°œìˆ˜: {np.isinf(numeric_df.values).sum()}")
                print(f"  - ìµœì†Ÿê°’: {numeric_df.min().min():.4f}")
                print(f"  - ìµœëŒ“ê°’: {numeric_df.max().max():.4f}")
                print(f"  - í‰ê· : {numeric_df.mean().mean():.4f}")
            else:
                print(f"  - âš ï¸ ìˆ«ìí˜• ì»¬ëŸ¼ ì—†ìŒ - dtype í™•ì¸ í•„ìš”")
        except Exception as e:
            print(f"  - í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")

        # ìš”êµ¬ë˜ëŠ” íŠ¹ì„± ì¤‘ ì²˜ìŒ 5ê°œì˜ ìµœê·¼ ê°’
        print(f"\n  ìš”êµ¬ íŠ¹ì„± ìµœê·¼ ê°’ (ë§ˆì§€ë§‰ í–‰):")
        for col in config['feat_cols'][:5]:
            if col in df_feat.columns:
                val = df_feat[col].iloc[-1]
                # ì•ˆì „í•œ í¬ë§· ì¶œë ¥ (ìˆ«ìê°€ ì•„ë‹ˆë©´ ê·¸ëƒ¥ ì¶œë ¥)
                try:
                    print(f"    {col}: {float(val):.6f}")
                except (ValueError, TypeError):
                    print(f"    {col}: {val} (íƒ€ì…: {type(val).__name__})")

    if len(df_feat) < config['seq_len']:
        return {
            "error": f"Insufficient features (got {len(df_feat)}, need {config['seq_len']})",
            "symbol": symbol
        }

    if len(df_feat.columns) != len(config['feat_cols']):
        return {
            "error": f"Feature mismatch (got {len(df_feat.columns)}, need {len(config['feat_cols'])})",
            "symbol": symbol
        }

    # ì‹œí€€ìŠ¤ ì¤€ë¹„ - ìˆ«ìí˜• ë³€í™˜ ê°•ì œ
    # âœ… ëª¨ë“  ì»¬ëŸ¼ì„ ëª…ì‹œì ìœ¼ë¡œ floatë¡œ ë³€í™˜ (ë¬¸ìì—´/object ì œê±°)
    for col in df_feat.columns:
        df_feat[col] = pd.to_numeric(df_feat[col], errors='coerce')

    # NaN/Infë¥¼ 0ìœ¼ë¡œ ëŒ€ì²´ (ì•ˆì „í•˜ê²Œ)
    df_feat = df_feat.fillna(0).replace([np.inf, -np.inf], 0)

    X = df_feat.iloc[-config['seq_len']:].values

    if debug:
        print(f"\n[DEBUG {symbol}] ì •ê·œí™” ì „ ë°ì´í„°:")
        print(f"  - X shape: {X.shape}")
        print(f"  - X dtype: {X.dtype}")

        # ì•ˆì „í•œ í†µê³„ ê³„ì‚° (ìˆ«ìí˜•ë§Œ)
        try:
            print(f"  - X í†µê³„: min={X.min():.4f}, max={X.max():.4f}, mean={X.mean():.4f}")
        except (TypeError, ValueError) as e:
            print(f"  - X í†µê³„: ê³„ì‚° ì‹¤íŒ¨ - {e}")
            print(f"  - X sample: {X[0, :5]}")  # ì²˜ìŒ 5ê°œ ê°’ë§Œ ì¶œë ¥
        print(f"  - scaler_mu: min={config['scaler_mu'].min():.4f}, max={config['scaler_mu'].max():.4f}")
        print(f"  - scaler_sd: min={config['scaler_sd'].min():.4f}, max={config['scaler_sd'].max():.4f}")

    # ì•ˆì „í•œ ì •ê·œí™” (scaler_sdê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ë³´ì •)
    safe_scaler_sd = np.maximum(config['scaler_sd'], 0.01)  # ìµœì†Œ 0.01
    X = (X - config['scaler_mu']) / (safe_scaler_sd + 1e-8)

    # ê·¹ë‹¨ê°’ í´ë¦¬í•‘ (ì •ê·œí™” í›„ -10 ~ 10 ë²”ìœ„ë¡œ ì œí•œ)
    X = np.clip(X, -10, 10)

    if debug:
        print(f"\n[DEBUG {symbol}] ì •ê·œí™” í›„ ë°ì´í„°:")
        print(f"  - X í†µê³„: min={X.min():.4f}, max={X.max():.4f}, mean={X.mean():.4f}")
        print(f"  - NaN ê°œìˆ˜: {np.isnan(X).sum()}")
        print(f"  - Inf ê°œìˆ˜: {np.isinf(X).sum()}")
        print(f"  - í´ë¦¬í•‘ ì ìš©: -10 ~ 10")

    X_tensor = torch.FloatTensor(X).unsqueeze(0)

    # ì¶”ë¡ 
    with torch.no_grad():
        # ì•™ìƒë¸” ëª¨ë¸ vs ë‹¨ì¼ ëª¨ë¸ êµ¬ë¶„
        is_ensemble = config.get('is_ensemble', False)

        if is_ensemble:
            # ì•™ìƒë¸” ëª¨ë¸: predict ë©”ì„œë“œ ì‚¬ìš©
            probs_tensor, uncertainty = model.predict(X_tensor, use_tta=False)
            probs = probs_tensor.squeeze().numpy()
            logits = None  # ì•™ìƒë¸”ì€ ì´ë¯¸ softmaxëœ í™•ë¥  ë°˜í™˜
        elif config['num_classes'] == 2:
            # ë‹¨ì¼ ëª¨ë¸ - Single-task (2-class)
            logits = model(X_tensor)
            probs = torch.softmax(logits, dim=1).squeeze().numpy()
        else:
            # ë‹¨ì¼ ëª¨ë¸ - Multi-task (3-class)
            logits_cls, _ = model(X_tensor)
            probs = torch.softmax(logits_cls, dim=1).squeeze().numpy()
            logits = logits_cls

    if debug:
        print(f"\n[DEBUG {symbol}] ëª¨ë¸ ì¶œë ¥:")
        is_ensemble = config.get('is_ensemble', False)

        if is_ensemble:
            print(f"  - ì•™ìƒë¸” ëª¨ë¸ (ì´ë¯¸ softmax ì ìš©)")
            print(f"  - uncertainty: {uncertainty.item():.6f}" if 'uncertainty' in locals() else "")
        elif config['num_classes'] == 2:
            print(f"  - logits: [{logits.squeeze()[0]:.4f}, {logits.squeeze()[1]:.4f}]")
        else:
            print(f"  - logits: [{logits.squeeze()[0]:.4f}, {logits.squeeze()[1]:.4f}, {logits.squeeze()[2]:.4f}]")

        print(f"  - probs: {probs}")
        print(f"  - confidence: {probs.max():.6f}")

    pred_class = int(probs.argmax())

    # ë°©í–¥ ë§¤í•‘
    if config['num_classes'] == 2:
        direction_map = {0: "Short", 1: "Long"}
    else:
        direction_map = {0: "Short", 1: "Flat", 2: "Long"}

    direction = direction_map[pred_class]
    confidence = float(probs.max())

    ticker = API.get_ticker(symbol)
    if ticker.get("retCode") == 0 and ticker.get("result", {}).get("list"):
        current_price = float(ticker["result"]["list"][0]["lastPrice"])
    else:
        # Ticker ì‹¤íŒ¨ ì‹œ dfì˜ ë§ˆì§€ë§‰ close ê°€ê²© ì‚¬ìš©
        current_price = float(df['close'].iloc[-1])
        if debug:
            print(f"  - âš ï¸ Ticker ì¡°íšŒ ì‹¤íŒ¨, dfì˜ close ì‚¬ìš©: ${current_price}")

    # ê°€ê²©ì´ 0ì´ê±°ë‚˜ ë„ˆë¬´ ì‘ìœ¼ë©´ ì—ëŸ¬ ë°˜í™˜
    if current_price <= 0 or current_price < 1e-10:
        return {
            "error": f"Invalid price: {current_price}",
            "symbol": symbol
        }

    return {
        "symbol": symbol,
        "direction": direction,
        "confidence": confidence,
        "current_price": current_price,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }


# ===== í™”ë©´ ì¶œë ¥ =====
def print_dashboard(account: Account, prices: Dict[str, float]):
    """ëŒ€ì‹œë³´ë“œ ì¶œë ¥"""
    os.system('clear' if os.name == 'posix' else 'cls')

    print("\n" + "=" * 110)
    print(f"{'ğŸ¯ í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ (ë ˆë²„ë¦¬ì§€ ' + str(LEVERAGE) + 'x, ' + str(len(MODELS)) + 'ê°œ ì‹¬ë³¼ ëª¨ë¸)':^110}")
    print("=" * 110)

    # ê³„ì¢Œ ì •ë³´
    total_value = account.get_total_value(prices)
    unrealized_pnl = total_value - account.balance
    total_return = (total_value / account.initial_capital - 1) * 100

    print(f"\nğŸ’° ê³„ì¢Œ í˜„í™©")
    print(f"   ì´ˆê¸° ìë³¸:     ${account.initial_capital:>12,.2f}")
    print(f"   í˜„ì¬ ì”ê³ :     ${account.balance:>12,.2f}")
    print(f"   ì‚¬ìš© ê°€ëŠ¥:     ${account.get_available_balance():>12,.2f}")
    print(f"   í‰ê°€ ì†ìµ:     ${unrealized_pnl:>+12,.2f}")
    print(f"   ì´ ìì‚°:       ${total_value:>12,.2f}  ({total_return:>+6.2f}%)")
    print(
        f"   ì‹¤í˜„ ì†ìµ:     ${account.total_pnl:>+12,.2f}  ({(account.total_pnl / account.initial_capital) * 100:>+6.2f}%)")

    # í¬ì§€ì…˜
    if account.positions:
        print(f"\nğŸ“ ë³´ìœ  í¬ì§€ì…˜ ({len(account.positions)}/{MAX_POSITIONS})")
        print(
            f"{'ì‹¬ë³¼':^12} | {'ë°©í–¥':^8} | {'ì§„ì…ê°€':^12} | {'í˜„ì¬ê°€':^12} | {'ì†ìµ(ROE)':^22} | {'ì²­ì‚°ê°€':^12} | {'ë³´ìœ ':^8}")
        print("-" * 110)

        for symbol, pos in account.positions.items():
            current_price = prices.get(symbol, pos.entry_price)

            # ğŸ”§ ê°€ê²© ìœ íš¨ì„± ê²€ì¦
            if current_price <= 0:
                print(f"âš ï¸  {symbol}: ê°€ê²© ë°ì´í„° ì—†ìŒ, ì§„ì…ê°€ ì‚¬ìš©")
                current_price = pos.entry_price

            pnl = pos.get_pnl(current_price)
            roe = pos.get_roe(current_price)
            hold_min = (datetime.now() - pos.entry_time).total_seconds() / 60
            liq_dist = pos.get_liquidation_distance(current_price)

            emoji = "ğŸ“ˆ" if pos.direction == "Long" else "ğŸ“‰"
            pnl_emoji = "ğŸŸ¢" if pnl > 0 else "ğŸ”´"
            liq_warning = "âš ï¸" if liq_dist < 3 else ""

            print(f"{symbol:^12} | {emoji} {pos.direction:^6} | ${pos.entry_price:>10,.4f} | "
                  f"${current_price:>10,.4f} | {pnl_emoji} ${pnl:>+8,.2f} ({roe:>+6.1f}%) | "
                  f"${pos.liquidation_price:>10,.4f}{liq_warning} | {hold_min:>6.1f}ë¶„")
    else:
        print(f"\nğŸ“ ë³´ìœ  í¬ì§€ì…˜: ì—†ìŒ")

    # í†µê³„
    stats = account.get_stats()
    if stats["total_trades"] > 0:
        print(f"\nğŸ“Š ê±°ë˜ í†µê³„")
        print(f"   ì´ ê±°ë˜:       {stats['total_trades']:>3}íšŒ")
        print(f"   ìŠ¹ë¥ :          {stats['win_rate']:>6.1f}% ({stats['wins']}ìŠ¹ {stats['losses']}íŒ¨)")
        if stats['liquidations'] > 0:
            print(f"   ê°•ì œ ì²­ì‚°:     {stats['liquidations']:>3}íšŒ ğŸ’€")
        print(f"   í‰ê·  ì†ìµ:     ${stats['avg_pnl']:>+12,.2f}")
        print(f"   í‰ê·  ROE:      {stats['avg_roe']:>+6.1f}%")
        print(f"   ìµœëŒ€ ìˆ˜ìµ:     ${stats['max_pnl']:>12,.2f}  (ROE: {stats['max_roe']:>+6.1f}%)")
        print(f"   ìµœëŒ€ ì†ì‹¤:     ${stats['min_pnl']:>12,.2f}  (ROE: {stats['min_roe']:>+6.1f}%)")
        if stats['wins'] > 0 and stats['losses'] > 0:
            rr = abs(stats['avg_win'] / stats['avg_loss'])
            print(f"   Risk/Reward:   {rr:>6.2f}")

    print("\n" + "=" * 110)


def save_trades(account: Account):
    """ê±°ë˜ ë‚´ì—­ ì €ì¥"""
    if not account.trades:
        return

    data = [asdict(t) for t in account.trades]
    with open(TRADE_LOG_FILE, 'w') as f:
        json.dump(data, f, indent=2)
    print(f"\nğŸ’¾ ê±°ë˜ ë‚´ì—­ ì €ì¥: {TRADE_LOG_FILE}")


# ===== ë©”ì¸ ë£¨í”„ =====
def test_api_connection():
    """API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")

    # Public API í…ŒìŠ¤íŠ¸
    print("   í…ŒìŠ¤íŠ¸ ì‹¬ë³¼: BTCUSDT")
    ticker = API.get_ticker("BTCUSDT")
    if ticker and ticker.get("retCode") == 0 and ticker.get("result", {}).get("list"):
        last_price = float(ticker["result"]["list"][0]["lastPrice"])
        print(f"   âœ“ Ticker ì¡°íšŒ ì„±ê³µ: ${last_price:,.2f}")
    else:
        print(f"   âœ— Ticker ì¡°íšŒ ì‹¤íŒ¨")
        print(f"   ì‘ë‹µ: {ticker}")
        return False

    df = API.get_klines("BTCUSDT", interval="5", limit=10)
    if not df.empty:
        print(f"   âœ“ Klines ì¡°íšŒ ì„±ê³µ: {len(df)}ê°œ ìº”ë“¤")
        print(f"   ìµœì‹  ê°€ê²©: ${df['close'].iloc[-1]:,.2f}")
    else:
        print(f"   âœ— Klines ì¡°íšŒ ì‹¤íŒ¨")
        return False

    print("\nâœ… API ì—°ê²° ì •ìƒ\n")
    return True


def should_scan_now():
    """í•­ìƒ ìŠ¤ìº” ê°€ëŠ¥ - 5ë¶„ë´‰ ëŒ€ê¸° ì—†ìŒ"""
    return True  # 5ë¶„ë´‰ì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ë°”ë¡œ ìŠ¤ìº”


def main():
    print("\n" + "=" * 110)
    print(f"{'ğŸ¯ í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹œì‘':^110}")
    print(f"{'ì´ˆê¸° ìë³¸: $' + f'{INITIAL_CAPITAL:,.2f}':^110}")
    print(f"{'ë ˆë²„ë¦¬ì§€: ' + f'{LEVERAGE}x (í¬ì§€ì…˜ í¬ê¸°: {POSITION_SIZE_PCT * 100:.0f}%)':^110}")
    print(f"{'ì‹ ë¢°ë„ ì„ê³„ê°’: ' + f'{CONF_THRESHOLD:.0%}':^110}")
    print(f"{'ì‚¬ìš© ëª¨ë¸: ' + str(len(MODELS)) + 'ê°œ ì‹¬ë³¼ë³„ ëª¨ë¸':^110}")
    print("=" * 110)

    # API ì—°ê²° í…ŒìŠ¤íŠ¸
    if not test_api_connection():
        print("\nâŒ API ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        print("\ní™•ì¸ ì‚¬í•­:")
        print("   1. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        print("   2. Bybit API ì„œë²„ ìƒíƒœ í™•ì¸")
        print("   3. ì‹¬ë³¼ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸ (ì˜ˆ: BTCUSDT)")
        return

    account = Account(INITIAL_CAPITAL)

    try:
        loop_count = 0
        while True:
            loop_count += 1
            current_time = datetime.now()

            # ìŠ¤ìº” ì‹œì‘
            print(f"\n{'=' * 110}")
            print(f"ğŸ”„ ìŠ¤ìº” ì‹œì‘! ({current_time.strftime('%H:%M:%S')})")

            # í˜„ì¬ ê°€ê²© ê°€ì ¸ì˜¤ê¸° (ëª¨ë¸ì´ ìˆëŠ” ì‹¬ë³¼ë§Œ)
            prices = {}
            for symbol in MODELS.keys():
                ticker = API.get_ticker(symbol)
                if ticker.get("retCode") == 0 and ticker.get("result", {}).get("list"):
                    try:
                        price = float(ticker["result"]["list"][0]["lastPrice"])
                        if price > 0:  # ğŸ”§ ìœ íš¨í•œ ê°€ê²©ë§Œ ì €ì¥
                            prices[symbol] = price
                        else:
                            print(f"âš ï¸  {symbol}: ê°€ê²©ì´ 0ì…ë‹ˆë‹¤. ì´ì „ ê°€ê²© ìœ ì§€")
                            # ì´ì „ ê°€ê²©ì´ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ skip
                            if symbol in prices:
                                pass  # ì´ì „ ê°€ê²© ìœ ì§€
                            # ìƒˆë¡œìš´ ì‹¬ë³¼ì´ë©´ ê°€ê²© ì—†ì´ skip
                    except (ValueError, KeyError, IndexError) as e:
                        print(f"âš ï¸  {symbol}: ê°€ê²© íŒŒì‹± ì‹¤íŒ¨ - {e}")
                else:
                    # ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ì´ì „ ê°€ê²© ìœ ì§€ (ì—†ìœ¼ë©´ skip)
                    if symbol not in prices:
                        print(f"âš ï¸  {symbol}: API ì¡°íšŒ ì‹¤íŒ¨, ê°€ê²© ì—†ìŒ")

            # í¬ì§€ì…˜ ê´€ë¦¬
            for symbol in list(account.positions.keys()):
                position = account.positions[symbol]
                current_price = prices.get(symbol, position.entry_price)

                # ğŸ”§ ê°€ê²© ìœ íš¨ì„± ê²€ì¦
                if current_price <= 0:
                    print(f"âš ï¸  {symbol}: ê°€ê²© ë°ì´í„° ì—†ìŒ, ì²­ì‚° íŒë‹¨ ê±´ë„ˆëœ€")
                    continue

                # ì²­ì‚° ì¡°ê±´ í™•ì¸
                should_close, reason = position.should_close(current_price, current_time)
                if should_close:
                    account.close_position(symbol, current_price, reason)
                else:
                    # ë°˜ëŒ€ ì‹ í˜¸ë¡œ ì²­ì‚°
                    result = predict(symbol, debug=False)
                    if "error" not in result and result.get("confidence", 0) >= CONF_THRESHOLD:
                        signal_dir = result["direction"]
                        if (position.direction == "Long" and signal_dir == "Short") or \
                                (position.direction == "Short" and signal_dir == "Long"):
                            account.close_position(symbol, current_price, "Reverse Signal")

            # ëŒ€ì‹œë³´ë“œ ì¶œë ¥
            print_dashboard(account, prices)

            # ì‹ í˜¸ ìŠ¤ìº” í…Œì´ë¸”
            print(f"\nğŸ” ì‹ í˜¸ ìŠ¤ìº” ({len(MODELS)}ê°œ ì‹¬ë³¼)")
            print(f"{'ì‹¬ë³¼':^12} | {'ê°€ê²©':^12} | {'ë°©í–¥':^10} | {'ì‹ ë¢°ë„':^8} | {'ì‹ í˜¸':^20}")
            print("-" * 80)

            # ì‹ í˜¸ ìŠ¤ìº” ë° ì§„ì… (ëª¨ë¸ì´ ìˆëŠ” ì‹¬ë³¼ë§Œ)
            debug_mode = (loop_count == 1)  # ì²« ìŠ¤ìº”ë§Œ ë””ë²„ê·¸ ëª¨ë“œ
            for symbol in MODELS.keys():
                result = predict(symbol, debug=debug_mode)

                if "error" in result:
                    print(f"{symbol:^12} | {'N/A':^12} | {'ì˜¤ë¥˜':^10} | {'N/A':^8} | âŒ {result.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    continue

                direction = result["direction"]
                confidence = result["confidence"]
                price = result["current_price"]

                # ë°©í–¥ ì´ëª¨ì§€
                dir_icon = {"Long": "ğŸ“ˆ", "Short": "ğŸ“‰", "Flat": "â–"}.get(direction, "â“")

                # ì‹ í˜¸ íŒë‹¨
                if confidence < CONF_THRESHOLD:
                    signal = f"âš ï¸  ì‹ í˜¸ ì•½í•¨ ({confidence:.1%})"
                elif direction == "Long":
                    signal = f"ğŸŸ¢ ë§¤ìˆ˜ ì‹ í˜¸ ({confidence:.1%})"
                elif direction == "Short":
                    signal = f"ğŸ”´ ë§¤ë„ ì‹ í˜¸ ({confidence:.1%})"
                else:
                    signal = f"âšª ê´€ë§ ({confidence:.1%})"

                print(
                    f"{symbol:^12} | ${price:>10,.4f} | {dir_icon} {direction:^8} | {confidence:>6.1%} | {signal:^20}")

                # ì§„ì… ì¡°ê±´
                if account.can_open_position(symbol) and confidence >= CONF_THRESHOLD and direction in ["Long",
                                                                                                        "Short"]:
                    account.open_position(symbol, direction, price)

            print(f"\n[ìŠ¤ìº” #{loop_count}] {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"ë‹¤ìŒ ìŠ¤ìº”ê¹Œì§€ {INTERVAL_SEC}ì´ˆ... (Ctrl+Cë¡œ ì¢…ë£Œ)")

            time.sleep(INTERVAL_SEC)

    except KeyboardInterrupt:
        print("\n\ní”„ë¡œê·¸ë¨ ì¢…ë£Œ ì¤‘...")
        print_dashboard(account, prices)
        save_trades(account)

        # ìµœì¢… í†µê³„
        stats = account.get_stats()
        if stats["total_trades"] > 0:
            print("\n" + "=" * 110)
            print(f"{'ğŸ“Š ìµœì¢… ê²°ê³¼':^110}")
            print("=" * 110)
            final_balance = account.balance
            final_return = (final_balance / account.initial_capital - 1) * 100
            print(f"   ìµœì¢… ì”ê³ :     ${final_balance:,.2f}")
            print(f"   ì´ ìˆ˜ìµë¥ :     {final_return:+.2f}%")
            print(f"   ì´ ê±°ë˜:       {stats['total_trades']}íšŒ")
            print(f"   ìŠ¹ë¥ :          {stats['win_rate']:.1f}%")
            print(f"   í‰ê·  ROE:      {stats['avg_roe']:+.1f}%")
            if stats['liquidations'] > 0:
                print(f"   ê°•ì œ ì²­ì‚°:     {stats['liquidations']}íšŒ ğŸ’€")
            print("=" * 110)

        print("\nâœ… í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()