# generate_signals.py
# -*- coding: utf-8 -*-
"""
ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‹ í˜¸ ìƒì„± + ì•Œë¦¼
"""
import os, json
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import torch
import torch.nn as nn


# ========= TCN ëª¨ë¸ êµ¬ì¡° =========
class Chomp1d(nn.Module):
    def __init__(self, c):
        super().__init__()
        self.c = c

    def forward(self, x):
        return x[:, :, :-self.c].contiguous() if self.c > 0 else x


def wconv(i, o, k, d):
    import torch.nn.utils as U
    pad = (k - 1) * d
    return U.weight_norm(nn.Conv1d(i, o, k, padding=pad, dilation=d))


class Block(nn.Module):
    def __init__(self, i, o, k, d, drop):
        super().__init__()
        self.c1 = wconv(i, o, k, d)
        self.h1 = Chomp1d((k - 1) * d)
        self.r1 = nn.ReLU()
        self.dr1 = nn.Dropout(drop)
        self.c2 = wconv(o, o, k, d)
        self.h2 = Chomp1d((k - 1) * d)
        self.r2 = nn.ReLU()
        self.dr2 = nn.Dropout(drop)
        self.ds = nn.Conv1d(i, o, 1) if i != o else None
        self.r = nn.ReLU()

    def forward(self, x):
        y = self.dr1(self.r1(self.h1(self.c1(x))))
        y = self.dr2(self.r2(self.h2(self.c2(y))))
        res = x if self.ds is None else self.ds(x)
        return self.r(y + res)


class TCN_Simple(nn.Module):
    def __init__(self, in_f, hidden=128, levels=6, k=3, drop=0.2):
        super().__init__()
        L = []
        ch = in_f
        for i in range(levels):
            L.append(Block(ch, hidden, k, 2 ** i, drop))
            ch = hidden
        self.tcn = nn.Sequential(*L)
        self.head_side = nn.Linear(hidden, 2)

    def forward(self, X):
        X = X.transpose(1, 2)
        H = self.tcn(X)[:, :, -1]
        return self.head_side(H)


# ========= í”¼ì²˜ ìƒì„± (train_tcn_daily.pyì™€ ë™ì¼) =========
def make_features(df):
    """train_tcn_daily.pyì˜ make_featuresì™€ ë™ì¼"""
    g = df.copy()
    g["logc"] = np.log(np.clip(g["close"].values, 1e-12, None))
    g["ret1"] = g.groupby("symbol")["logc"].diff().fillna(0.0)

    def roll_std(s, w):
        return s.rolling(w, min_periods=max(2, w // 3)).std()

    for w in (5, 10, 20, 60):
        g[f"rv{w}"] = g.groupby("symbol")["ret1"].apply(lambda s: roll_std(s, w)).reset_index(level=0, drop=True)

    def mom(gp, w):
        ema = gp["close"].ewm(span=w, adjust=False).mean()
        return gp["close"] / ema - 1.0

    for w in (5, 10, 20, 60):
        g[f"mom{w}"] = g.groupby("symbol", group_keys=False).apply(lambda s: mom(s, w))

    for w in (10, 20, 60):
        mu = g.groupby("symbol")["volume"].apply(lambda s: s.rolling(w, min_periods=max(2, w // 3)).mean()).reset_index(
            level=0, drop=True)
        sd = g.groupby("symbol")["volume"].apply(lambda s: s.rolling(w, min_periods=max(2, w // 3)).std()).reset_index(
            level=0, drop=True)
        sd = sd.replace(0, np.nan)
        g[f"vz{w}"] = (g["volume"] - mu) / sd.replace({0: np.nan}).fillna(1.0)

    prev_close = g.groupby("symbol")["close"].shift(1)
    tr = pd.concat([
        (g["high"] - g["low"]).abs(),
        (g["high"] - prev_close).abs(),
        (g["low"] - prev_close).abs()], axis=1).max(axis=1)
    g["atr14"] = tr.groupby(g["symbol"]).transform(lambda s: s.rolling(14, min_periods=5).mean())

    feats = ["ret1", "rv5", "rv10", "rv20", "rv60", "mom5", "mom10", "mom20", "mom60", "vz10", "vz20", "vz60", "atr14"]
    g = g.dropna(subset=feats).reset_index(drop=True)
    return g, feats


# ========= ëª¨ë¸ ë¡œë“œ =========
def load_model(ckpt_path):
    """ëª¨ë¸ ë¡œë“œ"""
    ckpt = torch.load(ckpt_path, map_location="cpu", weights_only=False)
    feat_cols = ckpt["feat_cols"]
    mu = np.asarray(ckpt["scaler_mu"], dtype=np.float32)
    sd = np.asarray(ckpt["scaler_sd"], dtype=np.float32)
    sd[sd == 0] = 1.0

    model = TCN_Simple(in_f=len(feat_cols))
    model.load_state_dict(ckpt["model"], strict=True)
    model.eval()

    return model, feat_cols, mu, sd


# ========= ì‹ í˜¸ ìƒì„± =========
def generate_signals(data_path, ckpt_path, seq_len=60, min_confidence=0.05):
    """ìµœì‹  ë°ì´í„°ë¡œ ì‹ í˜¸ ìƒì„±"""

    # ë°ì´í„° ë¡œë“œ
    print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ: {data_path}")
    if data_path.endswith('.parquet'):
        df = pd.read_parquet(data_path)
    else:
        df = pd.read_csv(data_path)

    # ë‚ ì§œ ì²˜ë¦¬
    date_col = "date" if "date" in df.columns else "timestamp"
    df[date_col] = pd.to_datetime(df[date_col], utc=True, errors='coerce')
    df = df.dropna(subset=[date_col])

    print(f"   â†’ {len(df):,}í–‰, {df[date_col].min().date()} ~ {df[date_col].max().date()}")
    print(f"   â†’ ì‹¬ë³¼: {df['symbol'].nunique()}ê°œ")

    # ëª¨ë¸ ë¡œë“œ
    print(f"\nğŸ¤– ëª¨ë¸ ë¡œë“œ: {ckpt_path}")
    model, feat_cols, mu, sd = load_model(ckpt_path)
    print(f"   â†’ í”¼ì²˜: {len(feat_cols)}ê°œ")

    # í”¼ì²˜ ìƒì„±
    print(f"\nâš™ï¸  í”¼ì²˜ ìƒì„± ì¤‘...")
    df_feat, _ = make_features(df)
    print(f"   â†’ {len(df_feat):,}í–‰ (í”¼ì²˜ ìƒì„± í›„)")

    signals = []
    processed = 0

    print(f"\nğŸ” ì‹ í˜¸ ìƒì„± ì¤‘...")
    for symbol, g in df_feat.groupby("symbol"):
        processed += 1
        if processed % 50 == 0:
            print(f"   ì§„í–‰: {processed}/{df_feat['symbol'].nunique()}")

        if len(g) < seq_len:
            continue

        # ìµœê·¼ 60ì¼ ë°ì´í„°
        recent = g.tail(seq_len)
        X = (recent[feat_cols].to_numpy(np.float32) - mu) / sd
        X_tensor = torch.from_numpy(X).unsqueeze(0)

        # ì˜ˆì¸¡
        with torch.no_grad():
            logits = model(X_tensor)
            probs = torch.softmax(logits, dim=1).cpu().numpy()[0]
            p_short, p_long = float(probs[0]), float(probs[1])

        # ì‹ í˜¸ ìƒì„±
        side = "LONG" if p_long > p_short else "SHORT"
        confidence = abs(p_long - p_short)

        # ë‚®ì€ ì‹ ë¢°ë„ í•„í„°ë§
        if confidence < min_confidence:
            continue

        # í˜„ì¬ê°€ ì •ë³´
        latest_date = recent.iloc[-1][date_col]
        latest_close = float(recent.iloc[-1]["close"])

        # TP/SL ê³„ì‚°
        if side == "LONG":
            entry_estimate = latest_close * 1.001  # ë‹¤ìŒ open ì¶”ì •
            tp_price = entry_estimate * 1.035  # +3.5%
            sl_price = entry_estimate * 0.9825  # -1.75%
        else:
            entry_estimate = latest_close * 0.999
            tp_price = entry_estimate * 0.965  # -3.5%
            sl_price = entry_estimate * 1.0175  # +1.75%

        signals.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "symbol": symbol,
            "side": side,
            "confidence": round(confidence, 3),
            "latest_close": round(latest_close, 2),
            "entry_estimate": round(entry_estimate, 2),
            "tp_price": round(tp_price, 2),
            "sl_price": round(sl_price, 2),
            "data_date": str(latest_date.date())
        })

    # ì‹ ë¢°ë„ ìˆœ ì •ë ¬
    signals = sorted(signals, key=lambda x: -x["confidence"])

    print(f"   â†’ ì™„ë£Œ: {len(signals)}ê°œ ì‹ í˜¸ ìƒì„±\n")

    return signals


# ========= ì¶œë ¥ ë° ì•Œë¦¼ =========
def print_signals(signals, top_n=20):
    """ì‹ í˜¸ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print(f"ğŸ¯ íŠ¸ë ˆì´ë”© ì‹ í˜¸ ({len(signals)}ê°œ ì‹¬ë³¼)")
    print(f"â° ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80 + "\n")

    # ì‚¬ì´ë“œë³„ ê°œìˆ˜
    long_count = sum(1 for s in signals if s["side"] == "LONG")
    short_count = sum(1 for s in signals if s["side"] == "SHORT")
    print(f"ğŸ“Š LONG: {long_count}ê°œ | SHORT: {short_count}ê°œ\n")

    # TOP ì‹ í˜¸
    print(f"ğŸ”¥ ìƒìœ„ {min(top_n, len(signals))}ê°œ ì‹ í˜¸ (ì‹ ë¢°ë„ ìˆœ):")
    print("-" * 80)

    for i, sig in enumerate(signals[:top_n], 1):
        emoji = "ğŸŸ¢" if sig["side"] == "LONG" else "ğŸ”´"
        print(f"{i:2d}. {emoji} {sig['symbol']:10s} | {sig['side']:5s} | "
              f"ì‹ ë¢°ë„: {sig['confidence']:.3f}")
        print(f"    í˜„ì¬ê°€: ${sig['latest_close']:,.2f} â†’ "
              f"ì§„ì…: ${sig['entry_estimate']:,.2f}")
        print(f"    TP: ${sig['tp_price']:,.2f} | SL: ${sig['sl_price']:,.2f}")
        print()


def save_signals(signals, output_path="trading_signals.csv"):
    """CSV ì €ì¥"""
    df = pd.DataFrame(signals)
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ ì‹ í˜¸ ì €ì¥: {output_path}")
    print(f"   â†’ {len(signals)}í–‰ ì €ì¥ë¨\n")


def create_checklist(signal):
    """ê±°ë˜ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸"""
    print(f"\nğŸ“‹ ê±°ë˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ - {signal['symbol']}")
    print("=" * 60)
    print(f"âœ… 1. ì‹ í˜¸ í™•ì¸: {signal['side']} (ì‹ ë¢°ë„ {signal['confidence']:.1%})")
    print(f"âœ… 2. ì§„ì…ê°€ í™•ì¸: ~${signal['entry_estimate']:,.2f}")
    print(f"âœ… 3. TP ì„¤ì •: ${signal['tp_price']:,.2f} (+3.5%)")
    print(f"âœ… 4. SL ì„¤ì •: ${signal['sl_price']:,.2f} (-1.75%)")
    print(f"âœ… 5. ë ˆë²„ë¦¬ì§€: 10ë°° (ìë³¸ 5% ì‚¬ìš©)")
    print(f"âœ… 6. í¬ì§€ì…˜ ìˆ˜: ìµœëŒ€ 5ê°œ ìœ ì§€")
    print("=" * 60)
    print("\nâš ï¸  ì‹¤í–‰ ì „ í™•ì¸ì‚¬í•­:")
    print("â–¡ ìµœê·¼ ë‰´ìŠ¤/ì´ë²¤íŠ¸ ì²´í¬")
    print("â–¡ í˜„ì¬ ì‹œì¥ ë³€ë™ì„± í™•ì¸")
    print("â–¡ ë‹¤ë¥¸ í¬ì§€ì…˜ê³¼ ìƒê´€ê´€ê³„ ì²´í¬")
    print("â–¡ ìê¸ˆ ì—¬ìœ  í™•ì¸")
    print("\nâ–¶ï¸  ë¬¸ì œì—†ìœ¼ë©´ ë§ˆì¼“ ì£¼ë¬¸ìœ¼ë¡œ ì§„ì…\n")


# ========= ë©”ì¸ =========
def main():
    import argparse

    parser = argparse.ArgumentParser(description="íŠ¸ë ˆì´ë”© ì‹ í˜¸ ìƒì„±ê¸°")
    parser.add_argument("--data", required=True, help="ë°ì´í„° CSV/Parquet íŒŒì¼")
    parser.add_argument("--ckpt", default="./models_daily/daily_simple_ep045.ckpt", help="ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸")
    parser.add_argument("--top", type=int, default=20, help="ìƒìœ„ Nê°œ ì‹ í˜¸ í‘œì‹œ")
    parser.add_argument("--save", action="store_true", help="CSVë¡œ ì €ì¥")
    parser.add_argument("--checklist", type=int, help="íŠ¹ì • ì‹ í˜¸ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ìˆœìœ„)")
    parser.add_argument("--min-conf", type=float, default=0.05, help="ìµœì†Œ ì‹ ë¢°ë„")
    args = parser.parse_args()

    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.data):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.data}")
        print(f"\nğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° íŒŒì¼:")
        for f in os.listdir('.'):
            if f.endswith(('.csv', '.parquet')):
                print(f"   - {f}")
        return

    if not os.path.exists(args.ckpt):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.ckpt}")
        return

    try:
        # ì‹ í˜¸ ìƒì„±
        signals = generate_signals(args.data, args.ckpt, min_confidence=args.min_conf)

        if not signals:
            print("âš ï¸  ìƒì„±ëœ ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("   â†’ --min-conf ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš” (í˜„ì¬: {:.2f})".format(args.min_conf))
            return

        # ì¶œë ¥
        print_signals(signals, top_n=args.top)

        # ì €ì¥
        if args.save:
            save_signals(signals)

        # ì²´í¬ë¦¬ìŠ¤íŠ¸
        if args.checklist and 1 <= args.checklist <= len(signals):
            create_checklist(signals[args.checklist - 1])

        print("\nâœ… ì™„ë£Œ!")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()