# bybit_futures_klines_fast.py
# -*- coding: utf-8 -*-
"""
Bybit USDT-Perp collector â€” fast paging
- ë‚´ë¦¼ì°¨ìˆœ ì‘ë‹µ íŠ¹ì„±ì— ë§ì¶° end ì»¤ì„œë¥¼ ê³¼ê±°ë¡œ ì´ë™(ì—­ë°©í–¥ í˜ì´ì§•)
- requests.Session ì¬ì‚¬ìš© + ë©€í‹°ìŠ¤ë ˆë”©
- ì¤‘ë³µ ì œê±° & ë²¡í„°í™” ë³€í™˜
- âœ… INTERVAL ì¼ë°˜í™” (1m~1h~ì¼ë´‰ ë“±), ì»¤ì„œ(step) ìë™ ê³„ì‚°
"""

import time
import requests
import pandas as pd
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# =====================
# ì„¤ì •
# =====================
SYMBOLS = [
    "ETHUSDT","BTCUSDT","SOLUSDT","XRPUSDT","DOGEUSDT",
    "BNBUSDT","ADAUSDT","LINKUSDT","UNIUSDT","TRXUSDT",
    "LTCUSDT","MNTUSDT","SUIUSDT","1000PEPEUSDT",
    "XLMUSDT","ARBUSDT","APTUSDT","OPUSDT","AVAXUSDT"
]
# ğŸ”½ ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ 1ì‹œê°„ë´‰ ìˆ˜ì§‘ë¨: "60"
# (ì˜ˆ: 1m="1", 3m="3", 5m="5", 15m="15", 30m="30", 60m="60", 120m="120", 240m="240", ì¼ë´‰="D", ì£¼ë´‰="W", ì›”ë´‰="M")
INTERVAL = "60"          # 1ì‹œê°„ë´‰
CATEGORY = "linear"      # Bybit Futures USDT Perpetual

today = datetime.utcnow()
start_date = today - timedelta(days=1000)   # 6ê°œì›”ì¹˜ ì˜ˆì‹œ (ì›í•˜ë©´ ì¡°ì •)
START = start_date.strftime("%Y-%m-%d %H:%M:%S")
END   = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")

BASE_URL = "https://api.bybit.com/v5/market/kline"
PAGE_LIMIT = 1000
MAX_WORKERS = min(8, len(SYMBOLS))  # ì ë‹¹í•œ ë™ì‹œì„±

def interval_to_ms(interval: str) -> int:
    """Bybit v5 interval ë¬¸ìì—´ì„ msë¡œ ë³€í™˜."""
    if interval in {"D", "d"}:
        return 24 * 60 * 60 * 1000
    if interval in {"W", "w"}:
        return 7 * 24 * 60 * 60 * 1000
    if interval in {"M"}:  # ì›”
        # ì›” ë‹¨ìœ„ëŠ” ê¸¸ì´ê°€ ê°€ë³€ì´ë¼ í˜ì´ì§• ìŠ¤í…ë§Œ ëŒ€ëµì¹˜(30ì¼)ë¡œ ì‚¬ìš©
        return 30 * 24 * 60 * 60 * 1000
    # ë¶„ ë˜ëŠ” ì‹œê°„(ë¶„ ë‹¨ìœ„ ìˆ«ì) ì²˜ë¦¬
    try:
        mins = int(interval)
        return mins * 60 * 1000
    except ValueError:
        raise ValueError(f"Unsupported interval: {interval}")

def to_ms(dt: str) -> int:
    # ëª…ì‹œì  UTCë¡œ í•´ì„
    return int(pd.Timestamp(dt, tz="UTC").timestamp() * 1000)

def fetch_ohlcv_descending(session: requests.Session, symbol: str, start_ms: int, end_ms: int, interval="1") -> pd.DataFrame:
    """
    Bybit ì‘ë‹µì€ ìµœì‹ â†’ê³¼ê±° ë‚´ë¦¼ì°¨ìˆœ.
    => startëŠ” ê³ ì •, end ì»¤ì„œë¥¼ 'ê°€ì¥ ì˜¤ë˜ëœ ts - PERIOD_MS'ë¡œ ë‹¹ê²¨ê°€ë©° í˜ì´ì§•.
    """
    period_ms = interval_to_ms(interval)
    end_cursor = end_ms
    pages = []

    while end_cursor >= start_ms:
        params = {
            "category": CATEGORY,
            "symbol": symbol,
            "interval": interval,
            "start": start_ms,
            "end": end_cursor,
            "limit": PAGE_LIMIT
        }
        resp = session.get(BASE_URL, params=params, timeout=15)
        j = resp.json()
        if j.get("retCode", 0) != 0:
            print(f"[WARN] {symbol} retCode={j.get('retCode')} retMsg={j.get('retMsg')}")
            break

        rows = j.get("result", {}).get("list", [])
        if not rows:
            break

        # rows: [[ts, open, high, low, close, volume, turnover], ...] (ë¬¸ìì—´)
        pages.extend(rows)

        # ì´ë²ˆ í˜ì´ì§€ì˜ ê°€ì¥ ê³¼ê±° ts ì°¾ê¸°
        oldest_ts = min(int(x[0]) for x in rows)

        # ë‹¤ìŒ í˜ì´ì§€ëŠ” ì´ë²ˆ ê°€ì¥ ê³¼ê±° ì§ì „ ìº”ë“¤ê¹Œì§€ë¡œ endë¥¼ ë‹¹ê¹€
        end_cursor = oldest_ts - period_ms

        # ë‚¨ì€ êµ¬ê°„ì´ limit ë¯¸ë§Œì´ë¼ë©´ ë‹¤ìŒ í•œ ë²ˆìœ¼ë¡œ ëë‚  ìˆ˜ ìˆìŒ
        if len(rows) < PAGE_LIMIT and end_cursor < start_ms:
            break

    if not pages:
        return pd.DataFrame()

    # DataFrame ìƒì„± (ë²¡í„°í™” ë³€í™˜)
    df = pd.DataFrame(pages, columns=["timestamp","open","high","low","close","volume","turnover"])

    # íƒ€ì… ë³€í™˜
    df["timestamp"] = pd.to_datetime(df["timestamp"].astype("int64"), unit="ms", utc=True)
    for col in ["open","high","low","close","volume","turnover"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    # ì¤‘ë³µ ì œê±°, ì‹œê°„ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬, ë²”ìœ„ í•„í„°
    df = df.drop_duplicates(subset=["timestamp"]).sort_values("timestamp")
    df = df[(df["timestamp"] >= pd.to_datetime(start_ms, unit="ms", utc=True)) &
            (df["timestamp"] <  pd.to_datetime(end_ms,   unit="ms", utc=True))].reset_index(drop=True)
    df.insert(1, "symbol", symbol)
    return df

def main():
    start_ms = to_ms(START)
    end_ms   = to_ms(END)

    suffix = INTERVAL.lower()
    save_csv = f"bybit_futures_{suffix}.csv"
    save_parquet = f"bybit_futures_{suffix}.parquet"

    all_df = []
    with requests.Session() as s:
        s.headers.update({"User-Agent": "bybit-fast-collector/1.1"})
        # ì‹¬ë³¼ ë³‘ë ¬ ìˆ˜ì§‘
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
            futs = {ex.submit(fetch_ohlcv_descending, s, sym, start_ms, end_ms, INTERVAL): sym for sym in SYMBOLS}
            for fut in as_completed(futs):
                sym = futs[fut]
                try:
                    df = fut.result()
                    if df.empty:
                        print(f"[WARN] {sym} no data.")
                    else:
                        print(f"[OK] {sym} rows={len(df)} {df['timestamp'].min()} ~ {df['timestamp'].max()}")
                        all_df.append(df)
                except Exception as e:
                    print(f"[ERR] {sym} {e}")

    if not all_df:
        print("[ERROR] No data collected.")
        return

    df_all = pd.concat(all_df, ignore_index=True)
    df_all.to_csv(save_csv, index=False)
    df_all.to_parquet(save_parquet, index=False)
    print(f"[DONE] Saved {len(df_all)} rows to {save_csv} / {save_parquet}")

if __name__ == "__main__":
    main()
